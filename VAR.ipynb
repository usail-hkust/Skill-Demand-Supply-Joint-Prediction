{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of processors:  48\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.api import ARIMA\n",
    "from statsmodels.tsa.api import VAR\n",
    "import statsmodels.api as sm\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "import torch\n",
    "from torchmetrics.functional import classification, accuracy, auroc, f1_score, confusion_matrix\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import multiprocessing as mp\n",
    "print(\"Number of processors: \", mp.cpu_count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "warnings.simplefilter('ignore', ConvergenceWarning)\n",
    "warnings.simplefilter('ignore', UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/data/wchao/data/skill_inflow_outflow/\"\n",
    "dataset = \"fin\"\n",
    "subgraph_num=7446\n",
    "subgraph_num = subgraph_num\n",
    "startdate = pd.Timestamp(2017,10,1)\n",
    "enddate = pd.Timestamp(2019,4,1)\n",
    "period = 'M'\n",
    "time_attr = pd.date_range(start=startdate, end=enddate, freq=period).to_period(period)\n",
    "time_attr = time_attr.to_series().astype(str)\n",
    "datasetinflow =  pd.read_csv(\n",
    "    os.path.join(data_dir, f\"skill_inflow_list_{dataset}.csv\"),\n",
    "    encoding='utf-8',\n",
    "    header=0,\n",
    "    on_bad_lines='warn',\n",
    ")\n",
    "datasetinflow.index = time_attr\n",
    "datasetinflow.drop(\"time_attr\", axis=1, inplace=True, errors=\"ignore\")\n",
    "datasetoutflow =  pd.read_csv(\n",
    "    os.path.join(data_dir, f\"skill_outflow_list_{dataset}.csv\"),\n",
    "    encoding='utf-8',\n",
    "    header=0,\n",
    "    on_bad_lines='warn'\n",
    ")\n",
    "datasetoutflow.index = time_attr\n",
    "datasetoutflow.drop(\"time_attr\", axis=1, inplace=True, errors=\"ignore\")\n",
    "datasetinflow = datasetinflow.iloc[:,:subgraph_num]\n",
    "datasetoutflow = datasetoutflow.iloc[:,:subgraph_num]\n",
    "time_range = datasetinflow.columns.value_counts().sort_index().index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_matrices(count, time_range):\n",
    "    '''get normalized company-position pairwise matrix data\n",
    "    '''\n",
    "    matrices = {}\n",
    "    # build matrix\n",
    "    for time in time_range:\n",
    "        matrix = count[time].astype('float32')\n",
    "        matrix[matrix.isna()] = 0.0\n",
    "        matrix += 1e-6  # avoid divided by 0\n",
    "        matrices[time] = torch.from_numpy(matrix.values)\n",
    "    # stack data\n",
    "    matrices = torch.stack(list(matrices.values()),dim=0).float()\n",
    "    # print(torch.std(matrices,dim=0,unbiased=True).shape)\n",
    "    # print((torch.std(matrices,dim=0,unbiased=True)==0).any())\n",
    "    # normalize data\n",
    "    print(matrices.shape)\n",
    "    matrices = F.normalize(matrices, dim=1)\n",
    "    # print(matrices.shape)\n",
    "    # print(matrices)\n",
    "    # matrices_submean = torch.sub(matrices, torch.mean(matrices, dim=0))\n",
    "    # matrices = torch.div(matrices_submean, torch.maximum(torch.std(matrices,dim=0,unbiased=True), torch.tensor(1)))\n",
    "    return matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7446, 18])\n",
      "torch.Size([7446, 18])\n"
     ]
    }
   ],
   "source": [
    "inflow_matrices = _get_matrices(datasetinflow, time_range)\n",
    "outflow_matrices = _get_matrices(datasetoutflow, time_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_labels(vec: torch.Tensor, class_num: int):\n",
    "    '''split all range for data and get value range for each labels\n",
    "    '''\n",
    "    vec_tmp: torch.Tensor = vec.reshape(-1)\n",
    "    vec_tmp, _ = vec_tmp.sort()\n",
    "    n = len(vec_tmp)\n",
    "    val_range_list: list = []\n",
    "    for i in range(class_num):\n",
    "        val_range_list.append(vec_tmp[(n // class_num) * i])\n",
    "    val_range_list.append(vec_tmp[-1])\n",
    "    return val_range_list\n",
    "\n",
    "# def _get_label_SAX(vec: torch.Tensor, class_num: int):\n",
    "    \n",
    "def _to_label(vec: torch.Tensor, val_range_list: list, class_num: int):\n",
    "    '''map continuous values to `class_num` discrete labels for `vec` using `val_range_list`\n",
    "    '''\n",
    "\n",
    "    def _to_label_(v: float, val_range_list: list, class_num: int):\n",
    "        if v < val_range_list[0]:\n",
    "            return 0\n",
    "        for i in range(class_num):\n",
    "            if val_range_list[i] <= v <= val_range_list[i + 1]:\n",
    "                return i\n",
    "        return class_num - 1\n",
    "\n",
    "    return vec.clone().apply_(lambda x: _to_label_(x, val_range_list, class_num)).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "val_range_list = []\n",
    "class_num = 5\n",
    "for i in range(1,3):\n",
    "    supply_x = inflow_matrices[:,:-i]\n",
    "    supply_y = inflow_matrices[:,inflow_matrices.shape[1]-i]\n",
    "    demand_x = outflow_matrices[:,:-i]\n",
    "    demand_y = outflow_matrices[:,outflow_matrices.shape[1]-i]\n",
    "    sample = {'supply_x': supply_x, 'supply_y': supply_y, \"demand_x\": demand_x, \"demand_y\": demand_y}\n",
    "    data.append(sample)\n",
    "\n",
    "for sample in data:\n",
    "    val_range_list_supply = _get_labels(sample[\"supply_y\"], class_num)\n",
    "    val_range_list_demand = _get_labels(sample[\"demand_y\"], class_num)\n",
    "    val_range_list.append({\"supply\": val_range_list_supply, \"demand\":val_range_list_demand})\n",
    "    sample[\"supply_y_label\"] = _to_label(sample[\"supply_y\"], val_range_list_supply, class_num)\n",
    "    sample[\"demand_y_label\"] = _to_label(sample[\"demand_y\"], val_range_list_demand, class_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = data[0]\n",
    "sup_or_dem = [\"supply\", \"demand\"]\n",
    "for idx, sample in enumerate(data):\n",
    "    for sd in sup_or_dem:\n",
    "        rand_num = np.random.normal(0,1e-5,sample[sd+\"_x\"].numpy().shape[1])\n",
    "        model = VAR(sample[sd+\"_x\"].numpy().T[:,:]+rand_num[...,None])\n",
    "        results = model.fit(maxlags=10,trend='ct')\n",
    "        pred = results.forecast(sample[sd+\"_x\"].numpy().T[:,:]+rand_num[...,None],1)\n",
    "        output = _to_label(torch.tensor(pred), val_range_list[idx][sd], class_num)\n",
    "        output = F.one_hot(output).float()\n",
    "        sample[sd+\"_y_output\"] = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arima_forecasting(sample, order):\n",
    "    model = ARIMA(sample, order=order)\n",
    "    model.initialize_approximate_diffuse()\n",
    "    results = model.fit()\n",
    "    return results.forecast()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|â–         | 337/7446 [01:34<34:29,  3.44it/s]"
     ]
    }
   ],
   "source": [
    "sample = data[0]\n",
    "sup_or_dem = [\"supply\", \"demand\"]\n",
    "for idx, sample in enumerate(data):\n",
    "    for sd in sup_or_dem:\n",
    "        pool = mp.Pool(mp.cpu_count())\n",
    "        pred = [[pool.apply(arima_forecasting, args=(sample[sd+\"_x\"].numpy()[i,:], (5,1,3))) for i in tqdm(range(sample[sd+\"_x\"].shape[0]))]]\n",
    "        pool.close()\n",
    "        output = _to_label(torch.tensor(pred), val_range_list[idx][sd], class_num)\n",
    "        output = F.one_hot(output)\n",
    "        sample[sd+\"_y_output\"] = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_metric(output: torch.Tensor, labels: torch.Tensor, class_num=10):\n",
    "    '''evaluate model in three classification metrics: accuracy, weighted f1 score and auroc\n",
    "    '''\n",
    "    pred = torch.argmax(output, dim=-1)\n",
    "    acc = classification.accuracy(pred, labels, task=\"multiclass\", num_classes=class_num)\n",
    "    # print(acc)\n",
    "    return acc\n",
    "\n",
    "def f1_metric(output: torch.Tensor, labels: torch.Tensor, class_num=10):\n",
    "    pred = torch.argmax(output, dim=-1)\n",
    "    weighted_f1 = f1_score(pred, labels, task=\"multiclass\", average='weighted', num_classes=class_num)\n",
    "    return weighted_f1\n",
    "\n",
    "def aucroc_metric(output: torch.Tensor, labels: torch.Tensor, class_num=10):\n",
    "    au = auroc(output, labels, task='multiclass', num_classes=class_num)\n",
    "    return au\n",
    "\n",
    "def top_k_acc(output, target, k=3):\n",
    "    with torch.no_grad():\n",
    "        pred = torch.topk(output, k, dim=1)[1]\n",
    "        assert pred.shape[0] == len(target)\n",
    "        correct = 0\n",
    "        for i in range(k):\n",
    "            correct += torch.sum(pred[:, i] == target).item()\n",
    "    return correct / len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.23357171, 0.23577361, 0.23718339, ..., 0.20466299, 0.20228831,\n",
       "        0.24525064]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "supply_accuracy: 0.3137255012989044\n",
      "supply_f1: 0.2790670096874237\n",
      "supplyauc 0.5711067914962769\n",
      "demand_accuracy: 0.3142626881599426\n",
      "demand_f1: 0.31815141439437866\n",
      "demandauc 0.5714113116264343\n",
      "combined_accuracy: 0.31399407982826233\n",
      "combined_f1: 0.30632609128952026\n",
      "combined_auc 0.5712568163871765\n"
     ]
    }
   ],
   "source": [
    "sup_or_dem = [\"supply\", \"demand\"]\n",
    "combined_output_list = []\n",
    "combined_label_list = []\n",
    "for sd in sup_or_dem:\n",
    "    output_list = []\n",
    "    label_list = []\n",
    "    for idx, sample in enumerate(data):\n",
    "        output_list.append(sample[sd+\"_y_output\"])\n",
    "        label_list.append(sample[sd+\"_y_label\"])\n",
    "    # print(output.shape)\n",
    "    output = torch.cat(output_list,dim=1).squeeze().float()\n",
    "    # print(output.shape)\n",
    "    label = torch.cat(label_list,dim=0)\n",
    "    # print(label.shape)\n",
    "    print(sd+\"_accuracy:\", accuracy_metric(output,label,class_num).item())\n",
    "    print(sd+\"_f1:\", f1_metric(output,label,class_num).item())\n",
    "    print(sd+\"auc\", aucroc_metric(output,label,class_num).item())\n",
    "    combined_output_list.append(output)\n",
    "    combined_label_list.append(label)\n",
    "combined_output = torch.cat(combined_output_list,dim=0)\n",
    "combined_label = torch.cat(combined_label_list,dim=0)\n",
    "print(\"combined_accuracy:\", accuracy_metric(combined_output,combined_label,class_num).item())\n",
    "print(\"combined_f1:\", f1_metric(combined_output,combined_label,class_num).item())\n",
    "print(\"combined_auc\", aucroc_metric(combined_output,combined_label,class_num).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skillkg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7c36a224ccd04e9589c7a3c9598e7c801c45f556ee5050852987b6b827bf8582"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
