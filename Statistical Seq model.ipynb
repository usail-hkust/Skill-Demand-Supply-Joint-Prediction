{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/wchao/envs/rapids-23.06/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of processors:  48\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "# from statsmodels.tsa.stattools import adfuller\n",
    "# from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "# from statsmodels.tsa.api import ARIMA\n",
    "import cupy as cp\n",
    "from cuml.tsa.arima import ARIMA\n",
    "# from statsmodels.tsa.api import VAR\n",
    "# import statsmodels.api as sm\n",
    "# from pandas.plotting import register_matplotlib_converters\n",
    "# register_matplotlib_converters()\n",
    "\n",
    "import torch\n",
    "from torchmetrics.functional import classification, accuracy, auroc, f1_score, confusion_matrix\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import multiprocessing as mp\n",
    "print(\"Number of processors: \", mp.cpu_count())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/data/wchao/data/skill_inflow_outflow/\"\n",
    "dataset = \"cons\"\n",
    "subgraph_num=7446\n",
    "subgraph_num = subgraph_num\n",
    "startdate = pd.Timestamp(2017,10,1)\n",
    "enddate = pd.Timestamp(2019,4,1)\n",
    "period = 'M'\n",
    "time_attr = pd.date_range(start=startdate, end=enddate, freq=period).to_period(period)\n",
    "time_attr = time_attr.to_series().astype(str)\n",
    "datasetinflow =  pd.read_csv(\n",
    "    os.path.join(data_dir, f\"skill_inflow_list_{dataset}.csv\"),\n",
    "    encoding='utf-8',\n",
    "    header=0,\n",
    "    on_bad_lines='warn',\n",
    ")\n",
    "datasetinflow.index = time_attr\n",
    "datasetinflow.drop(\"time_attr\", axis=1, inplace=True, errors=\"ignore\")\n",
    "datasetoutflow =  pd.read_csv(\n",
    "    os.path.join(data_dir, f\"skill_outflow_list_{dataset}.csv\"),\n",
    "    encoding='utf-8',\n",
    "    header=0,\n",
    "    on_bad_lines='warn'\n",
    ")\n",
    "datasetoutflow.index = time_attr\n",
    "datasetoutflow.drop(\"time_attr\", axis=1, inplace=True, errors=\"ignore\")\n",
    "datasetinflow = datasetinflow.iloc[:,:subgraph_num]\n",
    "datasetoutflow = datasetoutflow.iloc[:,:subgraph_num]\n",
    "time_range = datasetinflow.columns.value_counts().sort_index().index.tolist()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7446, 18])\n",
      "torch.Size([7446, 18])\n"
     ]
    }
   ],
   "source": [
    "def _get_matrices(count, time_range):\n",
    "    '''get normalized company-position pairwise matrix data\n",
    "    '''\n",
    "    matrices = {}\n",
    "    # build matrix\n",
    "    for time in time_range:\n",
    "        matrix = count[time].astype('float32')\n",
    "        matrix[matrix.isna()] = 0.0\n",
    "        matrix += 1e-6  # avoid divided by 0\n",
    "        matrices[time] = torch.from_numpy(matrix.values)\n",
    "    # stack data\n",
    "    matrices = torch.stack(list(matrices.values()),dim=0).float()\n",
    "    # print(torch.std(matrices,dim=0,unbiased=True).shape)\n",
    "    # print((torch.std(matrices,dim=0,unbiased=True)==0).any())\n",
    "    # normalize data\n",
    "    print(matrices.shape)\n",
    "    matrices = F.normalize(matrices, dim=1)\n",
    "    # print(matrices.shape)\n",
    "    # print(matrices)\n",
    "    # matrices_submean = torch.sub(matrices, torch.mean(matrices, dim=0))\n",
    "    # matrices = torch.div(matrices_submean, torch.maximum(torch.std(matrices,dim=0,unbiased=True), torch.tensor(1)))\n",
    "    return matrices\n",
    "\n",
    "inflow_matrices = _get_matrices(datasetinflow, time_range)\n",
    "outflow_matrices = _get_matrices(datasetoutflow, time_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7446, 18])\n",
      "torch.Size([7446, 18])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_labels(vec: torch.Tensor, class_num: int):\n",
    "    '''split all range for data and get value range for each labels\n",
    "    '''\n",
    "    vec_tmp: torch.Tensor = vec.reshape(-1)\n",
    "    vec_tmp, _ = vec_tmp.sort()\n",
    "    n = len(vec_tmp)\n",
    "    val_range_list: list = []\n",
    "    for i in range(class_num):\n",
    "        val_range_list.append(vec_tmp[(n // class_num) * i])\n",
    "    val_range_list.append(vec_tmp[-1])\n",
    "    return val_range_list\n",
    "\n",
    "# def _get_label_SAX(vec: torch.Tensor, class_num: int):\n",
    "    \n",
    "def _to_label(vec: torch.Tensor, val_range_list: list, class_num: int):\n",
    "    '''map continuous values to `class_num` discrete labels for `vec` using `val_range_list`\n",
    "    '''\n",
    "\n",
    "    def _to_label_(v: float, val_range_list: list, class_num: int):\n",
    "        if v < val_range_list[0]:\n",
    "            return 0\n",
    "        for i in range(class_num):\n",
    "            if val_range_list[i] <= v <= val_range_list[i + 1]:\n",
    "                return i\n",
    "        return class_num - 1\n",
    "\n",
    "    return vec.clone().apply_(lambda x: _to_label_(x, val_range_list, class_num)).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "val_range_list = []\n",
    "class_num = 5\n",
    "for i in range(1,3):\n",
    "    supply_x = inflow_matrices[:,:-i]\n",
    "    supply_y = inflow_matrices[:,inflow_matrices.shape[1]-i]\n",
    "    demand_x = outflow_matrices[:,:-i]\n",
    "    demand_y = outflow_matrices[:,outflow_matrices.shape[1]-i]\n",
    "    sample = {'supply_x': supply_x, 'supply_y': supply_y, \"demand_x\": demand_x, \"demand_y\": demand_y}\n",
    "    data.append(sample)\n",
    "\n",
    "for sample in data:\n",
    "    val_range_list_supply = _get_labels(sample[\"supply_y\"], class_num)\n",
    "    val_range_list_demand = _get_labels(sample[\"demand_y\"], class_num)\n",
    "    val_range_list.append({\"supply\": val_range_list_supply, \"demand\":val_range_list_demand})\n",
    "    sample[\"supply_y_label\"] = _to_label(sample[\"supply_y\"], val_range_list_supply, class_num)\n",
    "    sample[\"demand_y_label\"] = _to_label(sample[\"demand_y\"], val_range_list_demand, class_num)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 17)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = data[0]\n",
    "sample[\"supply_x\"].numpy()[:10,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ARIMA(sample[\"supply_x\"].numpy()[:2,:], order=(5,1,2))\n",
    "results = model.fit()\n",
    "model.forecast(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7446, 17])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = data[0]\n",
    "sd = \"supply\"\n",
    "length = 10\n",
    "pred = []\n",
    "for i in tqdm(range(length)):\n",
    "    model = ARIMA(sample[sd+\"_x\"].numpy()[:i,:], order=(sample[sd+\"_x\"].shape[1],1,int(sample[sd+\"_x\"].shape[1]/2)))\n",
    "    # model.initialize_approximate_diffuse()\n",
    "    results = model.fit()\n",
    "    pred.append(results.forecast()[0])\n",
    "output = _to_label(torch.tensor(pred), val_range_list[0][sd], class_num)\n",
    "output = F.one_hot(output)\n",
    "sample[sd+\"_y_output\"] = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = _to_label(torch.tensor(pred), val_range_list[0][sd], class_num)\n",
    "output = F.one_hot(output)\n",
    "sample[sd+\"_y_output\"] = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.68275778e-06, -1.93285781e-06,  1.84868182e-06, ...,\n",
       "        1.13720849e-06, -1.97905934e-06, -1.02878404e-06])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd = \"supply\"\n",
    "np.random.normal(0,1e-6,sample[sd+\"_x\"].numpy().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arima_forecasting(sample, order):\n",
    "    model = ARIMA(sample, order=order)\n",
    "    model.initialize_approximate_diffuse()\n",
    "    results = model.fit()\n",
    "    return results.forecast()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W] [18:00:30.375568] fit: Some batch members had optimizer problems\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_num = np.random.normal(0,1e-6,sample[sd+\"_x\"].numpy().shape[1])\n",
    "model = ARIMA(sample[sd+\"_x\"].numpy()[:100,:].T+rand_num[...,None], order=(5,1,3))\n",
    "results = model.fit()\n",
    "pred = results.forecast(1)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W] [10:20:37.231987] fit: Some batch members had optimizer problems\n",
      "[W] [10:22:40.574145] fit: Some batch members had optimizer problems\n",
      "[W] [10:25:44.806278] fit: Some batch members had optimizer problems\n",
      "[W] [10:27:39.245048] fit: Some batch members had optimizer problems\n"
     ]
    }
   ],
   "source": [
    "sample = data[0]\n",
    "\n",
    "sup_or_dem = [\"supply\", \"demand\"]\n",
    "for idx, sample in enumerate(data):\n",
    "    for sd in sup_or_dem:\n",
    "        pred = []\n",
    "        rand_num = np.random.normal(0,1e-6,sample[sd+\"_x\"].numpy().shape[1])\n",
    "        model = ARIMA(sample[sd+\"_x\"].numpy()[:,:].T+rand_num[...,None], order=(5,1,3))\n",
    "        # model.initialize_approximate_diffuse()\n",
    "        results = model.fit()\n",
    "        pred = results.forecast(1)\n",
    "        output = _to_label(torch.tensor(pred), val_range_list[idx][sd], class_num)\n",
    "        output = F.one_hot(output)\n",
    "        sample[sd+\"_y_output\"] = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100)\n",
      "[tensor(0.0009), tensor(0.1545), tensor(0.2184), tensor(0.2568), tensor(0.3135), tensor(0.8568)]\n"
     ]
    }
   ],
   "source": [
    "print(pred.shape)\n",
    "print(val_range_list[idx][sd])\n",
    "# output = _to_label(torch.tensor(pred), val_range_list[idx][sd], class_num)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "F1, Auc Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_metric(output: torch.Tensor, labels: torch.Tensor, class_num=10):\n",
    "    '''evaluate model in three classification metrics: accuracy, weighted f1 score and auroc\n",
    "    '''\n",
    "    pred = torch.argmax(output, dim=-1)\n",
    "    # print(pred.shape, labels.shape)\n",
    "    acc = classification.accuracy(pred, labels, task=\"multiclass\", num_classes=class_num)\n",
    "    # print(acc)\n",
    "    return acc\n",
    "\n",
    "def f1_metric(output: torch.Tensor, labels: torch.Tensor, class_num=10):\n",
    "    pred = torch.argmax(output, dim=-1)\n",
    "    weighted_f1 = f1_score(pred, labels, task=\"multiclass\", average='weighted', num_classes=class_num)\n",
    "    return weighted_f1\n",
    "\n",
    "def aucroc_metric(output: torch.Tensor, labels: torch.Tensor, class_num=10):\n",
    "    au = auroc(output, labels, task='multiclass', num_classes=class_num)\n",
    "    return au\n",
    "\n",
    "def top_k_acc(output, target, k=3):\n",
    "    with torch.no_grad():\n",
    "        pred = torch.topk(output, k, dim=1)[1]\n",
    "        assert pred.shape[0] == len(target)\n",
    "        correct = 0\n",
    "        for i in range(k):\n",
    "            correct += torch.sum(pred[:, i] == target).item()\n",
    "    return correct / len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "supply_accuracy: 0.34535321593284607\n",
      "supply_f1: 0.34514784812927246\n",
      "supplyauc 0.5908439755439758\n",
      "demand_accuracy: 0.3233279585838318\n",
      "demand_f1: 0.32575199007987976\n",
      "demandauc 0.577078640460968\n",
      "combined_accuracy: 0.33434057235717773\n",
      "combined_f1: 0.3375827670097351\n",
      "combined_auc 0.5839612483978271\n"
     ]
    }
   ],
   "source": [
    "sup_or_dem = [\"supply\", \"demand\"]\n",
    "combined_output_list = []\n",
    "combined_label_list = []\n",
    "for sd in sup_or_dem:\n",
    "    output_list = []\n",
    "    label_list = []\n",
    "    for idx, sample in enumerate(data):\n",
    "        output_list.append(sample[sd+\"_y_output\"])\n",
    "        label_list.append(sample[sd+\"_y_label\"])\n",
    "    # print(output.shape)\n",
    "    output = torch.cat(output_list,dim=1).squeeze().float()\n",
    "    # print(output.shape)\n",
    "    label = torch.cat(label_list,dim=0)\n",
    "    # print(label.shape)\n",
    "    print(sd+\"_accuracy:\", accuracy_metric(output,label,class_num).item())\n",
    "    print(sd+\"_f1:\", f1_metric(output,label,class_num).item())\n",
    "    print(sd+\"auc\", aucroc_metric(output,label,class_num).item())\n",
    "    combined_output_list.append(output)\n",
    "    combined_label_list.append(label)\n",
    "combined_output = torch.cat(combined_output_list,dim=0)\n",
    "combined_label = torch.cat(combined_label_list,dim=0)\n",
    "print(\"combined_accuracy:\", accuracy_metric(combined_output,combined_label,class_num).item())\n",
    "print(\"combined_f1:\", f1_metric(combined_output,combined_label,class_num).item())\n",
    "print(\"combined_auc\", aucroc_metric(combined_output,combined_label,class_num).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-23.06",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1859a107f808877adf59a5a8efc6bda1e343909577c06ae448800df6ecd8bb02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
