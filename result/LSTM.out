Loading data...
tensor([0.0218, 0.0086, 0.0078,  ..., 0.1089, 0.0023, 0.0502])
tensor([0.0218, 0.1370, 0.1415,  ..., 0.1400, 0.1826, 0.1525])
Constructing model...
LSTM(
  (criterion): NLLLoss()
  (demand_amplifier): Linear(in_features=1, out_features=128, bias=True)
  (supply_amplifier): Linear(in_features=1, out_features=128, bias=True)
  (demand_encoder): LSTM(128, 128, num_layers=3, batch_first=True)
  (supply_encoder): LSTM(128, 128, num_layers=3, batch_first=True)
  (demand_decoder): Sequential(
    (0): Linear(in_features=128, out_features=64, bias=True)
    (1): Dropout(p=0.2, inplace=False)
    (2): ReLU(inplace=True)
    (3): Linear(in_features=64, out_features=10, bias=True)
  )
  (supply_decoder): Sequential(
    (0): Linear(in_features=128, out_features=64, bias=True)
    (1): Dropout(p=0.2, inplace=False)
    (2): ReLU(inplace=True)
    (3): Linear(in_features=64, out_features=10, bias=True)
  )
)
wandb: Currently logged in as: wchao. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.13.10 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.5
wandb: Run data is saved locally in /home/wchao/SkillTrendPrediction/wandb/run-20230210_171409-2dz53t3p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run LSTM
wandb: ‚≠êÔ∏è View project at https://wandb.ai/wchao/SKillTrend
wandb: üöÄ View run at https://wandb.ai/wchao/SKillTrend/runs/2dz53t3p
Start Training...
Train Epoch: 1 [0/100088 (0%)] Loss: 4.615123
Train Epoch: 1 [11264/100088 (11%)] Loss: 4.478169
Train Epoch: 1 [22528/100088 (23%)] Loss: 4.456512
Train Epoch: 1 [33792/100088 (34%)] Loss: 4.393602
Train Epoch: 1 [45056/100088 (45%)] Loss: 4.370152
Train Epoch: 1 [56320/100088 (56%)] Loss: 4.269053
Train Epoch: 1 [67584/100088 (68%)] Loss: 4.380095
Train Epoch: 1 [78848/100088 (79%)] Loss: 4.208068
Train Epoch: 1 [90112/100088 (90%)] Loss: 4.156425
    epoch          : 1
    loss           : 4.341218230675678
    inflow_loss    : 2.2389356214172986
    outflow_loss   : 2.1022826195979607
    inflow_accuracy_metric: 0.1708090752363205
    inflow_f1_metric: 0.07448935508728027
    inflow_aucroc_metric: 0.536689281463623
    outflow_accuracy_metric: 0.19358374178409576
    outflow_f1_metric: 0.15439793467521667
    outflow_aucroc_metric: 0.657106339931488
    val_loss       : 4.433790319844296
    val_inflow_loss: 2.0840080349068892
    val_outflow_loss: 2.349782284937407
    val_inflow_accuracy_metric: 0.22602111101150513
    val_inflow_f1_metric: 0.10771460086107254
    val_inflow_aucroc_metric: 0.5187638998031616
    val_outflow_accuracy_metric: 0.1094914972782135
    val_outflow_f1_metric: 0.07328972965478897
    val_outflow_aucroc_metric: 0.5022034645080566
Train Epoch: 2 [0/100088 (0%)] Loss: 4.167636
Train Epoch: 2 [11264/100088 (11%)] Loss: 4.124416
Train Epoch: 2 [22528/100088 (23%)] Loss: 4.089612
Train Epoch: 2 [33792/100088 (34%)] Loss: 3.969389
Train Epoch: 2 [45056/100088 (45%)] Loss: 3.991275
Train Epoch: 2 [56320/100088 (56%)] Loss: 3.940492
Train Epoch: 2 [67584/100088 (68%)] Loss: 4.171870
Train Epoch: 2 [78848/100088 (79%)] Loss: 3.921921
Train Epoch: 2 [90112/100088 (90%)] Loss: 3.916441
    epoch          : 2
    loss           : 3.974163146651521
    inflow_loss    : 2.053357567714185
    outflow_loss   : 1.920805584411232
    inflow_accuracy_metric: 0.24314990639686584
    inflow_f1_metric: 0.18530020117759705
    inflow_aucroc_metric: 0.6537100076675415
    outflow_accuracy_metric: 0.262076199054718
    outflow_f1_metric: 0.23032304644584656
    outflow_aucroc_metric: 0.7462735176086426
    val_loss       : 4.269426559147082
    val_inflow_loss: 1.9211599230766296
    val_outflow_loss: 2.3482666203850195
    val_inflow_accuracy_metric: 0.28239789605140686
    val_inflow_f1_metric: 0.20603685081005096
    val_inflow_aucroc_metric: 0.691629946231842
    val_outflow_accuracy_metric: 0.1353207230567932
    val_outflow_f1_metric: 0.097624771296978
    val_outflow_aucroc_metric: 0.4569874405860901
Train Epoch: 3 [0/100088 (0%)] Loss: 3.750584
Train Epoch: 3 [11264/100088 (11%)] Loss: 3.776161
Train Epoch: 3 [22528/100088 (23%)] Loss: 3.994818
Train Epoch: 3 [33792/100088 (34%)] Loss: 3.759000
Train Epoch: 3 [45056/100088 (45%)] Loss: 3.734859
Train Epoch: 3 [56320/100088 (56%)] Loss: 3.766091
Train Epoch: 3 [67584/100088 (68%)] Loss: 3.740749
Train Epoch: 3 [78848/100088 (79%)] Loss: 3.732029
Train Epoch: 3 [90112/100088 (90%)] Loss: 3.732499
    epoch          : 3
    loss           : 3.75354196222461
    inflow_loss    : 1.9050136415325865
    outflow_loss   : 1.8485283279905513
    inflow_accuracy_metric: 0.2884967625141144
    inflow_f1_metric: 0.24940524995326996
    inflow_aucroc_metric: 0.73138028383255
    outflow_accuracy_metric: 0.29156917333602905
    outflow_f1_metric: 0.2617962956428528
    outflow_aucroc_metric: 0.7672945857048035
    val_loss       : 4.050677851626747
    val_inflow_loss: 1.8103733470565395
    val_outflow_loss: 2.240304482610602
    val_inflow_accuracy_metric: 0.3038925528526306
    val_inflow_f1_metric: 0.2792607247829437
    val_inflow_aucroc_metric: 0.7400263547897339
    val_outflow_accuracy_metric: 0.13872326910495758
    val_outflow_f1_metric: 0.11598975956439972
    val_outflow_aucroc_metric: 0.4928537607192993
Train Epoch: 4 [0/100088 (0%)] Loss: 3.652052
Train Epoch: 4 [11264/100088 (11%)] Loss: 3.686929
Train Epoch: 4 [22528/100088 (23%)] Loss: 3.638495
Train Epoch: 4 [33792/100088 (34%)] Loss: 3.692491
Train Epoch: 4 [45056/100088 (45%)] Loss: 3.683094
Train Epoch: 4 [56320/100088 (56%)] Loss: 3.405398
Train Epoch: 4 [67584/100088 (68%)] Loss: 3.555620
Train Epoch: 4 [78848/100088 (79%)] Loss: 3.611004
Train Epoch: 4 [90112/100088 (90%)] Loss: 3.482719
    epoch          : 4
    loss           : 3.633680366739935
    inflow_loss    : 1.8238681171621596
    outflow_loss   : 1.809812265999463
    inflow_accuracy_metric: 0.3206561207771301
    inflow_f1_metric: 0.2895677387714386
    inflow_aucroc_metric: 0.7606531977653503
    outflow_accuracy_metric: 0.32207855582237244
    outflow_f1_metric: 0.29293522238731384
    outflow_aucroc_metric: 0.7791199088096619
    val_loss       : 3.9628293326026514
    val_inflow_loss: 1.7302902372259843
    val_outflow_loss: 2.2325391079250134
    val_inflow_accuracy_metric: 0.33474165201187134
    val_inflow_f1_metric: 0.3124076724052429
    val_inflow_aucroc_metric: 0.7678569555282593
    val_outflow_accuracy_metric: 0.14498013257980347
    val_outflow_f1_metric: 0.1257016807794571
    val_outflow_aucroc_metric: 0.5529116988182068
Train Epoch: 5 [0/100088 (0%)] Loss: 3.607362
Train Epoch: 5 [11264/100088 (11%)] Loss: 3.638483
Train Epoch: 5 [22528/100088 (23%)] Loss: 3.654520
Train Epoch: 5 [33792/100088 (34%)] Loss: 3.549807
Train Epoch: 5 [45056/100088 (45%)] Loss: 3.523849
Train Epoch: 5 [56320/100088 (56%)] Loss: 3.539415
Train Epoch: 5 [67584/100088 (68%)] Loss: 3.546006
Train Epoch: 5 [78848/100088 (79%)] Loss: 3.413678
Train Epoch: 5 [90112/100088 (90%)] Loss: 3.431137
    epoch          : 5
    loss           : 3.550126547716102
    inflow_loss    : 1.793143818573076
    outflow_loss   : 1.7569827175870234
    inflow_accuracy_metric: 0.33309492468833923
    inflow_f1_metric: 0.30477073788642883
    inflow_aucroc_metric: 0.7709078788757324
    outflow_accuracy_metric: 0.34571725130081177
    outflow_f1_metric: 0.31963562965393066
    outflow_aucroc_metric: 0.7943438291549683
    val_loss       : 3.9146936378980937
    val_inflow_loss: 1.7665528968760842
    val_outflow_loss: 2.1481407441590963
    val_inflow_accuracy_metric: 0.31753015518188477
    val_inflow_f1_metric: 0.3078150749206543
    val_inflow_aucroc_metric: 0.7613142132759094
    val_outflow_accuracy_metric: 0.17233073711395264
    val_outflow_f1_metric: 0.15732461214065552
    val_outflow_aucroc_metric: 0.5921403169631958
Train Epoch: 6 [0/100088 (0%)] Loss: 3.552630
Train Epoch: 6 [11264/100088 (11%)] Loss: 3.635663
Train Epoch: 6 [22528/100088 (23%)] Loss: 3.444416
Train Epoch: 6 [33792/100088 (34%)] Loss: 3.511414
Train Epoch: 6 [45056/100088 (45%)] Loss: 3.511776
Train Epoch: 6 [56320/100088 (56%)] Loss: 3.417629
Train Epoch: 6 [67584/100088 (68%)] Loss: 3.392593
Train Epoch: 6 [78848/100088 (79%)] Loss: 3.499524
Train Epoch: 6 [90112/100088 (90%)] Loss: 3.416334
    epoch          : 6
    loss           : 3.481411617629382
    inflow_loss    : 1.7840962495122636
    outflow_loss   : 1.6973153602103799
    inflow_accuracy_metric: 0.3365533649921417
    inflow_f1_metric: 0.30964937806129456
    inflow_aucroc_metric: 0.7736879587173462
    outflow_accuracy_metric: 0.3690249025821686
    outflow_f1_metric: 0.35473141074180603
    outflow_aucroc_metric: 0.8111810088157654
    val_loss       : 3.7948129679027356
    val_inflow_loss: 1.8068138643314964
    val_outflow_loss: 1.9879991223937588
    val_inflow_accuracy_metric: 0.2928556799888611
    val_inflow_f1_metric: 0.2914234399795532
    val_inflow_aucroc_metric: 0.7551106810569763
    val_outflow_accuracy_metric: 0.19681674242019653
    val_outflow_f1_metric: 0.18003205955028534
    val_outflow_aucroc_metric: 0.6331887245178223
Train Epoch: 7 [0/100088 (0%)] Loss: 3.379547
Train Epoch: 7 [11264/100088 (11%)] Loss: 3.466679
Train Epoch: 7 [22528/100088 (23%)] Loss: 3.343558
Train Epoch: 7 [33792/100088 (34%)] Loss: 3.530355
Train Epoch: 7 [45056/100088 (45%)] Loss: 3.243672
Train Epoch: 7 [56320/100088 (56%)] Loss: 3.410943
Train Epoch: 7 [67584/100088 (68%)] Loss: 3.388560
Train Epoch: 7 [78848/100088 (79%)] Loss: 3.378508
Train Epoch: 7 [90112/100088 (90%)] Loss: 3.376669
    epoch          : 7
    loss           : 3.392597036702292
    inflow_loss    : 1.7576202269719572
    outflow_loss   : 1.6349768072974926
    inflow_accuracy_metric: 0.34899893403053284
    inflow_f1_metric: 0.3240617513656616
    inflow_aucroc_metric: 0.7815002202987671
    outflow_accuracy_metric: 0.3885313868522644
    outflow_f1_metric: 0.37605875730514526
    outflow_aucroc_metric: 0.8268561959266663
    val_loss       : 3.725135796948483
    val_inflow_loss: 1.6561287610154403
    val_outflow_loss: 2.0690070390701294
    val_inflow_accuracy_metric: 0.3697265684604645
    val_inflow_f1_metric: 0.3656684458255768
    val_inflow_aucroc_metric: 0.786699116230011
    val_outflow_accuracy_metric: 0.19870135188102722
    val_outflow_f1_metric: 0.1850787103176117
    val_outflow_aucroc_metric: 0.6374041438102722
Train Epoch: 8 [0/100088 (0%)] Loss: 3.413848
Train Epoch: 8 [11264/100088 (11%)] Loss: 3.271025
Train Epoch: 8 [22528/100088 (23%)] Loss: 3.323680
Train Epoch: 8 [33792/100088 (34%)] Loss: 3.281844
Train Epoch: 8 [45056/100088 (45%)] Loss: 3.289799
Train Epoch: 8 [56320/100088 (56%)] Loss: 3.263070
Train Epoch: 8 [67584/100088 (68%)] Loss: 3.350827
Train Epoch: 8 [78848/100088 (79%)] Loss: 3.478236
Train Epoch: 8 [90112/100088 (90%)] Loss: 3.477921
    epoch          : 8
    loss           : 3.3543030485814933
    inflow_loss    : 1.742376032532478
    outflow_loss   : 1.6119270123997513
    inflow_accuracy_metric: 0.35489848256111145
    inflow_f1_metric: 0.3320908844470978
    inflow_aucroc_metric: 0.785353422164917
    outflow_accuracy_metric: 0.39462605118751526
    outflow_f1_metric: 0.382610946893692
    outflow_aucroc_metric: 0.8324992060661316
    val_loss       : 3.5894304953123393
    val_inflow_loss: 1.6215532861257855
    val_outflow_loss: 1.9678772248719867
    val_inflow_accuracy_metric: 0.3920367360115051
    val_inflow_f1_metric: 0.3808870017528534
    val_inflow_aucroc_metric: 0.8008381724357605
    val_outflow_accuracy_metric: 0.20108620822429657
    val_outflow_f1_metric: 0.18390633165836334
    val_outflow_aucroc_metric: 0.6566486954689026
Train Epoch: 9 [0/100088 (0%)] Loss: 3.240762
Train Epoch: 9 [11264/100088 (11%)] Loss: 3.348298
Train Epoch: 9 [22528/100088 (23%)] Loss: 3.297882
Train Epoch: 9 [33792/100088 (34%)] Loss: 3.186901
Train Epoch: 9 [45056/100088 (45%)] Loss: 3.270177
Train Epoch: 9 [56320/100088 (56%)] Loss: 3.341293
Train Epoch: 9 [67584/100088 (68%)] Loss: 3.262452
Train Epoch: 9 [78848/100088 (79%)] Loss: 3.332961
Train Epoch: 9 [90112/100088 (90%)] Loss: 3.299244
    epoch          : 9
    loss           : 3.3085930894832223
    inflow_loss    : 1.7249125187494316
    outflow_loss   : 1.5836805658681052
    inflow_accuracy_metric: 0.3626296818256378
    inflow_f1_metric: 0.34027013182640076
    inflow_aucroc_metric: 0.789813220500946
    outflow_accuracy_metric: 0.40212804079055786
    outflow_f1_metric: 0.3900988698005676
    outflow_aucroc_metric: 0.8385180830955505
    val_loss       : 3.672477910393163
    val_inflow_loss: 1.636176137547744
    val_outflow_loss: 2.0363017728454187
    val_inflow_accuracy_metric: 0.3912520706653595
    val_inflow_f1_metric: 0.37791067361831665
    val_inflow_aucroc_metric: 0.7974621653556824
    val_outflow_accuracy_metric: 0.2082647979259491
    val_outflow_f1_metric: 0.18025727570056915
    val_outflow_aucroc_metric: 0.654205322265625
Train Epoch: 10 [0/100088 (0%)] Loss: 3.196141
Train Epoch: 10 [11264/100088 (11%)] Loss: 3.229384
Train Epoch: 10 [22528/100088 (23%)] Loss: 3.442937
Train Epoch: 10 [33792/100088 (34%)] Loss: 3.339542
Train Epoch: 10 [45056/100088 (45%)] Loss: 3.327662
Train Epoch: 10 [56320/100088 (56%)] Loss: 3.323975
Train Epoch: 10 [67584/100088 (68%)] Loss: 3.248024
Train Epoch: 10 [78848/100088 (79%)] Loss: 3.220801
Train Epoch: 10 [90112/100088 (90%)] Loss: 3.341028
    epoch          : 10
    loss           : 3.300841192809903
    inflow_loss    : 1.7134175610785582
    outflow_loss   : 1.5874236140932356
    inflow_accuracy_metric: 0.366352379322052
    inflow_f1_metric: 0.344215452671051
    inflow_aucroc_metric: 0.7929738163948059
    outflow_accuracy_metric: 0.39837417006492615
    outflow_f1_metric: 0.38656309247016907
    outflow_aucroc_metric: 0.8377574682235718
    val_loss       : 3.622462410675852
    val_inflow_loss: 1.636975806010397
    val_outflow_loss: 1.9854866140767147
    val_inflow_accuracy_metric: 0.3711588680744171
    val_inflow_f1_metric: 0.3845275342464447
    val_inflow_aucroc_metric: 0.8024226427078247
    val_outflow_accuracy_metric: 0.2099849134683609
    val_outflow_f1_metric: 0.19225360453128815
    val_outflow_aucroc_metric: 0.6582350134849548
Train Epoch: 11 [0/100088 (0%)] Loss: 3.127595
Train Epoch: 11 [11264/100088 (11%)] Loss: 3.213631
Train Epoch: 11 [22528/100088 (23%)] Loss: 3.366389
Train Epoch: 11 [33792/100088 (34%)] Loss: 3.250846
Train Epoch: 11 [45056/100088 (45%)] Loss: 3.276954
Train Epoch: 11 [56320/100088 (56%)] Loss: 3.200142
Train Epoch: 11 [67584/100088 (68%)] Loss: 3.312666
Train Epoch: 11 [78848/100088 (79%)] Loss: 3.221591
Train Epoch: 11 [90112/100088 (90%)] Loss: 3.267428
    epoch          : 11
    loss           : 3.2667472070577195
    inflow_loss    : 1.702263055407271
    outflow_loss   : 1.5644841455683416
    inflow_accuracy_metric: 0.371746301651001
    inflow_f1_metric: 0.349832147359848
    inflow_aucroc_metric: 0.7953360080718994
    outflow_accuracy_metric: 0.40690314769744873
    outflow_f1_metric: 0.3950407803058624
    outflow_aucroc_metric: 0.8425310850143433
    val_loss       : 3.493445114085549
    val_inflow_loss: 1.584683989223681
    val_outflow_loss: 1.9087611185876947
    val_inflow_accuracy_metric: 0.4094812273979187
    val_inflow_f1_metric: 0.4031110405921936
    val_inflow_aucroc_metric: 0.8128628730773926
    val_outflow_accuracy_metric: 0.21780428290367126
    val_outflow_f1_metric: 0.20142902433872223
    val_outflow_aucroc_metric: 0.6725365519523621
Train Epoch: 12 [0/100088 (0%)] Loss: 3.273200
Train Epoch: 12 [11264/100088 (11%)] Loss: 3.247257
Train Epoch: 12 [22528/100088 (23%)] Loss: 3.119130
Train Epoch: 12 [33792/100088 (34%)] Loss: 3.254809
Train Epoch: 12 [45056/100088 (45%)] Loss: 3.216170
Train Epoch: 12 [56320/100088 (56%)] Loss: 3.290346
Train Epoch: 12 [67584/100088 (68%)] Loss: 3.211168
Train Epoch: 12 [78848/100088 (79%)] Loss: 3.238933
Train Epoch: 12 [90112/100088 (90%)] Loss: 3.195344
    epoch          : 12
    loss           : 3.2506183142564735
    inflow_loss    : 1.6977525347349596
    outflow_loss   : 1.5528657801297245
    inflow_accuracy_metric: 0.3748980760574341
    inflow_f1_metric: 0.35178515315055847
    inflow_aucroc_metric: 0.7967526316642761
    outflow_accuracy_metric: 0.40901699662208557
    outflow_f1_metric: 0.39709046483039856
    outflow_aucroc_metric: 0.8448467254638672
    val_loss       : 3.492148436998066
    val_inflow_loss: 1.6036961580577649
    val_outflow_loss: 1.8884522695290415
    val_inflow_accuracy_metric: 0.407970130443573
    val_inflow_f1_metric: 0.41085270047187805
    val_inflow_aucroc_metric: 0.8178884983062744
    val_outflow_accuracy_metric: 0.21765349805355072
    val_outflow_f1_metric: 0.19314680993556976
    val_outflow_aucroc_metric: 0.6746395826339722
Train Epoch: 13 [0/100088 (0%)] Loss: 3.256793
Train Epoch: 13 [11264/100088 (11%)] Loss: 3.103956
Train Epoch: 13 [22528/100088 (23%)] Loss: 3.255034
Train Epoch: 13 [33792/100088 (34%)] Loss: 3.168704
Train Epoch: 13 [45056/100088 (45%)] Loss: 3.212982
Train Epoch: 13 [56320/100088 (56%)] Loss: 3.167217
Train Epoch: 13 [67584/100088 (68%)] Loss: 3.241321
Train Epoch: 13 [78848/100088 (79%)] Loss: 3.187269
Train Epoch: 13 [90112/100088 (90%)] Loss: 3.184225
    epoch          : 13
    loss           : 3.226082900348975
    inflow_loss    : 1.6793251311292454
    outflow_loss   : 1.5467577564473054
    inflow_accuracy_metric: 0.3817828595638275
    inflow_f1_metric: 0.3595467209815979
    inflow_aucroc_metric: 0.8011581897735596
    outflow_accuracy_metric: 0.4093326926231384
    outflow_f1_metric: 0.3986775875091553
    outflow_aucroc_metric: 0.8464945554733276
    val_loss       : 3.626116263239007
    val_inflow_loss: 1.588044235580846
    val_outflow_loss: 2.0380719994243823
    val_inflow_accuracy_metric: 0.3983381390571594
    val_inflow_f1_metric: 0.4064177870750427
    val_inflow_aucroc_metric: 0.8164796829223633
    val_outflow_accuracy_metric: 0.21406592428684235
    val_outflow_f1_metric: 0.18619990348815918
    val_outflow_aucroc_metric: 0.6645693182945251
Train Epoch: 14 [0/100088 (0%)] Loss: 3.156826
Train Epoch: 14 [11264/100088 (11%)] Loss: 3.181739
Train Epoch: 14 [22528/100088 (23%)] Loss: 3.225425
Train Epoch: 14 [33792/100088 (34%)] Loss: 3.139601
Train Epoch: 14 [45056/100088 (45%)] Loss: 3.316566
Train Epoch: 14 [56320/100088 (56%)] Loss: 3.188526
Train Epoch: 14 [67584/100088 (68%)] Loss: 3.353179
Train Epoch: 14 [78848/100088 (79%)] Loss: 3.041794
Train Epoch: 14 [90112/100088 (90%)] Loss: 3.263025
    epoch          : 14
    loss           : 3.2128129978569184
    inflow_loss    : 1.6739854624076766
    outflow_loss   : 1.5388275415313488
    inflow_accuracy_metric: 0.38460391759872437
    inflow_f1_metric: 0.36287564039230347
    inflow_aucroc_metric: 0.8026779890060425
    outflow_accuracy_metric: 0.4102404713630676
    outflow_f1_metric: 0.3990803360939026
    outflow_aucroc_metric: 0.8480018973350525
    val_loss       : 3.587293028831482
    val_inflow_loss: 1.6014353883893866
    val_outflow_loss: 1.9858576592646147
    val_inflow_accuracy_metric: 0.4132743775844574
    val_inflow_f1_metric: 0.4096517562866211
    val_inflow_aucroc_metric: 0.8064681887626648
    val_outflow_accuracy_metric: 0.22213883697986603
    val_outflow_f1_metric: 0.19754141569137573
    val_outflow_aucroc_metric: 0.6684977412223816
Train Epoch: 15 [0/100088 (0%)] Loss: 3.203365
Train Epoch: 15 [11264/100088 (11%)] Loss: 3.203699
Train Epoch: 15 [22528/100088 (23%)] Loss: 3.176183
Train Epoch: 15 [33792/100088 (34%)] Loss: 3.171309
Train Epoch: 15 [45056/100088 (45%)] Loss: 3.227680
Train Epoch: 15 [56320/100088 (56%)] Loss: 3.160925
Train Epoch: 15 [67584/100088 (68%)] Loss: 3.182716
Train Epoch: 15 [78848/100088 (79%)] Loss: 3.279194
Train Epoch: 15 [90112/100088 (90%)] Loss: 3.183867
    epoch          : 15
    loss           : 3.2010947186119703
    inflow_loss    : 1.66629799896357
    outflow_loss   : 1.5347967093088188
    inflow_accuracy_metric: 0.3868544101715088
    inflow_f1_metric: 0.3652202785015106
    inflow_aucroc_metric: 0.804635763168335
    outflow_accuracy_metric: 0.41150182485580444
    outflow_f1_metric: 0.40014728903770447
    outflow_aucroc_metric: 0.8488966822624207
    val_loss       : 3.419722324923465
    val_inflow_loss: 1.568294042035153
    val_outflow_loss: 1.8514282860253986
    val_inflow_accuracy_metric: 0.4116639494895935
    val_inflow_f1_metric: 0.40772759914398193
    val_inflow_aucroc_metric: 0.81594318151474
    val_outflow_accuracy_metric: 0.22301603853702545
    val_outflow_f1_metric: 0.20886912941932678
    val_outflow_aucroc_metric: 0.6738225817680359
Train Epoch: 16 [0/100088 (0%)] Loss: 3.090576
Train Epoch: 16 [11264/100088 (11%)] Loss: 3.057320
Train Epoch: 16 [22528/100088 (23%)] Loss: 3.288036
Train Epoch: 16 [33792/100088 (34%)] Loss: 3.169604
Train Epoch: 16 [45056/100088 (45%)] Loss: 3.196613
Train Epoch: 16 [56320/100088 (56%)] Loss: 3.158386
Train Epoch: 16 [67584/100088 (68%)] Loss: 3.660094
Train Epoch: 16 [78848/100088 (79%)] Loss: 3.482643
Train Epoch: 16 [90112/100088 (90%)] Loss: 3.265919
    epoch          : 16
    loss           : 3.2886191533536326
    inflow_loss    : 1.7634137540447468
    outflow_loss   : 1.5252053968760433
    inflow_accuracy_metric: 0.34805551171302795
    inflow_f1_metric: 0.3190474510192871
    inflow_aucroc_metric: 0.7755162119865417
    outflow_accuracy_metric: 0.41415828466415405
    outflow_f1_metric: 0.40397828817367554
    outflow_aucroc_metric: 0.8508477210998535
    val_loss       : 3.71074326414811
    val_inflow_loss: 1.6790622378650464
    val_outflow_loss: 2.031681023145977
    val_inflow_accuracy_metric: 0.37319421768188477
    val_inflow_f1_metric: 0.38281702995300293
    val_inflow_aucroc_metric: 0.8007802963256836
    val_outflow_accuracy_metric: 0.22971491515636444
    val_outflow_f1_metric: 0.21154744923114777
    val_outflow_aucroc_metric: 0.6756793260574341
Train Epoch: 17 [0/100088 (0%)] Loss: 3.252737
Train Epoch: 17 [11264/100088 (11%)] Loss: 3.255578
Train Epoch: 17 [22528/100088 (23%)] Loss: 3.217062
Train Epoch: 17 [33792/100088 (34%)] Loss: 3.233451
Train Epoch: 17 [45056/100088 (45%)] Loss: 3.272492
Train Epoch: 17 [56320/100088 (56%)] Loss: 3.224959
Train Epoch: 17 [67584/100088 (68%)] Loss: 3.094460
Train Epoch: 17 [78848/100088 (79%)] Loss: 3.186606
Train Epoch: 17 [90112/100088 (90%)] Loss: 3.218397
    epoch          : 17
    loss           : 3.2241305648064125
    inflow_loss    : 1.7007309472074315
    outflow_loss   : 1.5233996139497172
    inflow_accuracy_metric: 0.37442782521247864
    inflow_f1_metric: 0.34967944025993347
    inflow_aucroc_metric: 0.7949562668800354
    outflow_accuracy_metric: 0.4133855402469635
    outflow_f1_metric: 0.40240344405174255
    outflow_aucroc_metric: 0.8513672351837158
    val_loss       : 3.4989918219415763
    val_inflow_loss: 1.5912393802090694
    val_outflow_loss: 1.9077524448695935
    val_inflow_accuracy_metric: 0.3986876308917999
    val_inflow_f1_metric: 0.39970511198043823
    val_inflow_aucroc_metric: 0.8102660179138184
    val_outflow_accuracy_metric: 0.2222382128238678
    val_outflow_f1_metric: 0.2008601576089859
    val_outflow_aucroc_metric: 0.6785831451416016
Train Epoch: 18 [0/100088 (0%)] Loss: 3.182951
Train Epoch: 18 [11264/100088 (11%)] Loss: 3.124552
Train Epoch: 18 [22528/100088 (23%)] Loss: 3.098045
Train Epoch: 18 [33792/100088 (34%)] Loss: 3.142800
Train Epoch: 18 [45056/100088 (45%)] Loss: 3.267061
Train Epoch: 18 [56320/100088 (56%)] Loss: 3.223295
Train Epoch: 18 [67584/100088 (68%)] Loss: 3.172614
Train Epoch: 18 [78848/100088 (79%)] Loss: 3.056726
Train Epoch: 18 [90112/100088 (90%)] Loss: 3.188059
    epoch          : 18
    loss           : 3.1841785360355765
    inflow_loss    : 1.6631161886818555
    outflow_loss   : 1.5210623437044573
    inflow_accuracy_metric: 0.38919100165367126
    inflow_f1_metric: 0.36596232652664185
    inflow_aucroc_metric: 0.8049156069755554
    outflow_accuracy_metric: 0.41438424587249756
    outflow_f1_metric: 0.4030613601207733
    outflow_aucroc_metric: 0.8516411781311035
    val_loss       : 3.3984652381194267
    val_inflow_loss: 1.5657760908729152
    val_outflow_loss: 1.832689150383598
    val_inflow_accuracy_metric: 0.40188461542129517
    val_inflow_f1_metric: 0.41253048181533813
    val_inflow_aucroc_metric: 0.8208979368209839
    val_outflow_accuracy_metric: 0.22270764410495758
    val_outflow_f1_metric: 0.2097785770893097
    val_outflow_aucroc_metric: 0.6838613748550415
Train Epoch: 19 [0/100088 (0%)] Loss: 3.057949
Train Epoch: 19 [11264/100088 (11%)] Loss: 3.263416
Train Epoch: 19 [22528/100088 (23%)] Loss: 3.219814
Train Epoch: 19 [33792/100088 (34%)] Loss: 3.056982
Train Epoch: 19 [45056/100088 (45%)] Loss: 3.160480
Train Epoch: 19 [56320/100088 (56%)] Loss: 3.105619
Train Epoch: 19 [67584/100088 (68%)] Loss: 3.250005
Train Epoch: 19 [78848/100088 (79%)] Loss: 3.216944
Train Epoch: 19 [90112/100088 (90%)] Loss: 3.158928
    epoch          : 19
    loss           : 3.164065429142543
    inflow_loss    : 1.652068560828968
    outflow_loss   : 1.511996857973994
    inflow_accuracy_metric: 0.3922421932220459
    inflow_f1_metric: 0.37027600407600403
    inflow_aucroc_metric: 0.807873010635376
    outflow_accuracy_metric: 0.41492846608161926
    outflow_f1_metric: 0.4046463072299957
    outflow_aucroc_metric: 0.8533434867858887
    val_loss       : 3.5830166026165613
    val_inflow_loss: 1.5543289717875028
    val_outflow_loss: 2.028687618280712
    val_inflow_accuracy_metric: 0.4124349057674408
    val_inflow_f1_metric: 0.4213108420372009
    val_inflow_aucroc_metric: 0.8204362988471985
    val_outflow_accuracy_metric: 0.21806126832962036
    val_outflow_f1_metric: 0.1886487454175949
    val_outflow_aucroc_metric: 0.6706790328025818
Train Epoch: 20 [0/100088 (0%)] Loss: 3.271821
Train Epoch: 20 [11264/100088 (11%)] Loss: 3.203793
Train Epoch: 20 [22528/100088 (23%)] Loss: 3.205582
Train Epoch: 20 [33792/100088 (34%)] Loss: 3.074512
Train Epoch: 20 [45056/100088 (45%)] Loss: 3.121105
Train Epoch: 20 [56320/100088 (56%)] Loss: 3.216362
Train Epoch: 20 [67584/100088 (68%)] Loss: 3.056428
Train Epoch: 20 [78848/100088 (79%)] Loss: 3.129619
Train Epoch: 20 [90112/100088 (90%)] Loss: 3.144542
    epoch          : 20
    loss           : 3.153982937335968
    inflow_loss    : 1.6436885735210107
    outflow_loss   : 1.5102943613821147
    inflow_accuracy_metric: 0.39452287554740906
    inflow_f1_metric: 0.37306466698646545
    inflow_aucroc_metric: 0.8099950551986694
    outflow_accuracy_metric: 0.4161361753940582
    outflow_f1_metric: 0.4053661525249481
    outflow_aucroc_metric: 0.853884220123291
    val_loss       : 3.4255694652858533
    val_inflow_loss: 1.530842414027766
    val_outflow_loss: 1.8947270638064335
    val_inflow_accuracy_metric: 0.42748427391052246
    val_inflow_f1_metric: 0.43539634346961975
    val_inflow_aucroc_metric: 0.8285030126571655
    val_outflow_accuracy_metric: 0.22710047662258148
    val_outflow_f1_metric: 0.21280236542224884
    val_outflow_aucroc_metric: 0.682211697101593
Train Epoch: 21 [0/100088 (0%)] Loss: 3.190967
Train Epoch: 21 [11264/100088 (11%)] Loss: 3.131357
Train Epoch: 21 [22528/100088 (23%)] Loss: 3.297214
Train Epoch: 21 [33792/100088 (34%)] Loss: 3.184967
Train Epoch: 21 [45056/100088 (45%)] Loss: 3.187991
Train Epoch: 21 [56320/100088 (56%)] Loss: 3.088034
Train Epoch: 21 [67584/100088 (68%)] Loss: 3.122216
Train Epoch: 21 [78848/100088 (79%)] Loss: 3.107931
Train Epoch: 21 [90112/100088 (90%)] Loss: 3.095275
    epoch          : 21
    loss           : 3.150191072298556
    inflow_loss    : 1.6436680208663552
    outflow_loss   : 1.5065230648128354
    inflow_accuracy_metric: 0.39617258310317993
    inflow_f1_metric: 0.37436655163764954
    inflow_aucroc_metric: 0.8098117113113403
    outflow_accuracy_metric: 0.41675013303756714
    outflow_f1_metric: 0.40611571073532104
    outflow_aucroc_metric: 0.8545416593551636
    val_loss       : 3.603791023555555
    val_inflow_loss: 1.5731777642902576
    val_outflow_loss: 2.0306132529911243
    val_inflow_accuracy_metric: 0.4200109839439392
    val_inflow_f1_metric: 0.42112982273101807
    val_inflow_aucroc_metric: 0.8128597140312195
    val_outflow_accuracy_metric: 0.21222245693206787
    val_outflow_f1_metric: 0.19536010921001434
    val_outflow_aucroc_metric: 0.662188708782196
Train Epoch: 22 [0/100088 (0%)] Loss: 3.177835
Train Epoch: 22 [11264/100088 (11%)] Loss: 3.134226
Train Epoch: 22 [22528/100088 (23%)] Loss: 3.119138
Train Epoch: 22 [33792/100088 (34%)] Loss: 3.106928
Train Epoch: 22 [45056/100088 (45%)] Loss: 3.252477
Train Epoch: 22 [56320/100088 (56%)] Loss: 3.171033
Train Epoch: 22 [67584/100088 (68%)] Loss: 3.157191
Train Epoch: 22 [78848/100088 (79%)] Loss: 3.092287
Train Epoch: 22 [90112/100088 (90%)] Loss: 3.052273
    epoch          : 22
    loss           : 3.139624894881735
    inflow_loss    : 1.6366104921516107
    outflow_loss   : 1.503014401513703
    inflow_accuracy_metric: 0.39785757660865784
    inflow_f1_metric: 0.3767804801464081
    inflow_aucroc_metric: 0.811701774597168
    outflow_accuracy_metric: 0.417988657951355
    outflow_f1_metric: 0.4075239300727844
    outflow_aucroc_metric: 0.8550352454185486
    val_loss       : 3.5157774749555086
    val_inflow_loss: 1.5428460710927059
    val_outflow_loss: 1.972931400725716
    val_inflow_accuracy_metric: 0.4307737350463867
    val_inflow_f1_metric: 0.43260735273361206
    val_inflow_aucroc_metric: 0.8252097368240356
    val_outflow_accuracy_metric: 0.2341899573802948
    val_outflow_f1_metric: 0.2046671062707901
    val_outflow_aucroc_metric: 0.6850764155387878
Train Epoch: 23 [0/100088 (0%)] Loss: 3.154449
Train Epoch: 23 [11264/100088 (11%)] Loss: 3.027480
Train Epoch: 23 [22528/100088 (23%)] Loss: 3.123022
Train Epoch: 23 [33792/100088 (34%)] Loss: 3.016643
Train Epoch: 23 [45056/100088 (45%)] Loss: 3.143066
Train Epoch: 23 [56320/100088 (56%)] Loss: 3.220037
Train Epoch: 23 [67584/100088 (68%)] Loss: 3.144986
Train Epoch: 23 [78848/100088 (79%)] Loss: 3.117645
Train Epoch: 23 [90112/100088 (90%)] Loss: 3.129497
    epoch          : 23
    loss           : 3.127697473886062
    inflow_loss    : 1.629683453209546
    outflow_loss   : 1.4980140194600942
    inflow_accuracy_metric: 0.40013954043388367
    inflow_f1_metric: 0.37936362624168396
    inflow_aucroc_metric: 0.8136463165283203
    outflow_accuracy_metric: 0.41773924231529236
    outflow_f1_metric: 0.40757495164871216
    outflow_aucroc_metric: 0.8559460639953613
    val_loss       : 3.4691209981316016
    val_inflow_loss: 1.5370553418209678
    val_outflow_loss: 1.932065653173547
    val_inflow_accuracy_metric: 0.43188732862472534
    val_inflow_f1_metric: 0.43590039014816284
    val_inflow_aucroc_metric: 0.8231187462806702
    val_outflow_accuracy_metric: 0.2249794453382492
    val_outflow_f1_metric: 0.2149249166250229
    val_outflow_aucroc_metric: 0.6725723147392273
Train Epoch: 24 [0/100088 (0%)] Loss: 3.119577
Train Epoch: 24 [11264/100088 (11%)] Loss: 3.113017
Train Epoch: 24 [22528/100088 (23%)] Loss: 3.167790
Train Epoch: 24 [33792/100088 (34%)] Loss: 3.142786
Train Epoch: 24 [45056/100088 (45%)] Loss: 3.070464
Train Epoch: 24 [56320/100088 (56%)] Loss: 3.076087
Train Epoch: 24 [67584/100088 (68%)] Loss: 3.115501
Train Epoch: 24 [78848/100088 (79%)] Loss: 3.171917
Train Epoch: 24 [90112/100088 (90%)] Loss: 3.194251
    epoch          : 24
    loss           : 3.123291623835661
    inflow_loss    : 1.6282098329797083
    outflow_loss   : 1.49508177929995
    inflow_accuracy_metric: 0.4014163315296173
    inflow_f1_metric: 0.38111865520477295
    inflow_aucroc_metric: 0.8138712644577026
    outflow_accuracy_metric: 0.4194776117801666
    outflow_f1_metric: 0.4093547761440277
    outflow_aucroc_metric: 0.8568814992904663
    val_loss       : 3.419661051348636
    val_inflow_loss: 1.5438465507406938
    val_outflow_loss: 1.8758144974708557
    val_inflow_accuracy_metric: 0.4384080469608307
    val_inflow_f1_metric: 0.4354695677757263
    val_inflow_aucroc_metric: 0.8311014175415039
    val_outflow_accuracy_metric: 0.22642886638641357
    val_outflow_f1_metric: 0.2083527147769928
    val_outflow_aucroc_metric: 0.6803573966026306
Train Epoch: 25 [0/100088 (0%)] Loss: 3.134273
Train Epoch: 25 [11264/100088 (11%)] Loss: 3.086671
Train Epoch: 25 [22528/100088 (23%)] Loss: 3.153674
Train Epoch: 25 [33792/100088 (34%)] Loss: 3.111673
Train Epoch: 25 [45056/100088 (45%)] Loss: 3.265653
Train Epoch: 25 [56320/100088 (56%)] Loss: 3.058189
Train Epoch: 25 [67584/100088 (68%)] Loss: 2.980097
Train Epoch: 25 [78848/100088 (79%)] Loss: 3.191152
Train Epoch: 25 [90112/100088 (90%)] Loss: 3.053932
    epoch          : 25
    loss           : 3.113303174777907
    inflow_loss    : 1.6264601459308548
    outflow_loss   : 1.4868430270224202
    inflow_accuracy_metric: 0.40227943658828735
    inflow_f1_metric: 0.3812767565250397
    inflow_aucroc_metric: 0.8143311142921448
    outflow_accuracy_metric: 0.42303991317749023
    outflow_f1_metric: 0.4127042293548584
    outflow_aucroc_metric: 0.8582022190093994
    val_loss       : 3.516241901799252
    val_inflow_loss: 1.5950750708580017
    val_outflow_loss: 1.921166812118731
    val_inflow_accuracy_metric: 0.4128974974155426
    val_inflow_f1_metric: 0.41074010729789734
    val_inflow_aucroc_metric: 0.7989852428436279
    val_outflow_accuracy_metric: 0.22804275155067444
    val_outflow_f1_metric: 0.21340245008468628
    val_outflow_aucroc_metric: 0.6803950071334839
Train Epoch: 26 [0/100088 (0%)] Loss: 3.062579
Train Epoch: 26 [11264/100088 (11%)] Loss: 3.052324
Train Epoch: 26 [22528/100088 (23%)] Loss: 3.016893
Train Epoch: 26 [33792/100088 (34%)] Loss: 3.029526
Train Epoch: 26 [45056/100088 (45%)] Loss: 3.193178
Train Epoch: 26 [56320/100088 (56%)] Loss: 3.161006
Train Epoch: 26 [67584/100088 (68%)] Loss: 3.038061
Train Epoch: 26 [78848/100088 (79%)] Loss: 3.176780
Train Epoch: 26 [90112/100088 (90%)] Loss: 3.184278
    epoch          : 26
    loss           : 3.113584522081881
    inflow_loss    : 1.6280965567851553
    outflow_loss   : 1.4854879725952537
    inflow_accuracy_metric: 0.4001312255859375
    inflow_f1_metric: 0.3791784942150116
    inflow_aucroc_metric: 0.8142269253730774
    outflow_accuracy_metric: 0.4227766692638397
    outflow_f1_metric: 0.4126007556915283
    outflow_aucroc_metric: 0.8586845397949219
    val_loss       : 3.569808238431027
    val_inflow_loss: 1.544494933203647
    val_outflow_loss: 2.0253132989532068
    val_inflow_accuracy_metric: 0.43358686566352844
    val_inflow_f1_metric: 0.42877528071403503
    val_inflow_aucroc_metric: 0.8209872245788574
    val_outflow_accuracy_metric: 0.2318188101053238
    val_outflow_f1_metric: 0.19807372987270355
    val_outflow_aucroc_metric: 0.6801097989082336
Train Epoch: 27 [0/100088 (0%)] Loss: 3.052413
Train Epoch: 27 [11264/100088 (11%)] Loss: 3.078612
Train Epoch: 27 [22528/100088 (23%)] Loss: 3.073271
Train Epoch: 27 [33792/100088 (34%)] Loss: 3.110628
Train Epoch: 27 [45056/100088 (45%)] Loss: 3.121317
Train Epoch: 27 [56320/100088 (56%)] Loss: 3.191544
Train Epoch: 27 [67584/100088 (68%)] Loss: 3.084053
Train Epoch: 27 [78848/100088 (79%)] Loss: 3.175053
Train Epoch: 27 [90112/100088 (90%)] Loss: 3.094764
    epoch          : 27
    loss           : 3.0995541312256636
    inflow_loss    : 1.6183267527697038
    outflow_loss   : 1.4812273833216454
    inflow_accuracy_metric: 0.40320396423339844
    inflow_f1_metric: 0.38342127203941345
    inflow_aucroc_metric: 0.816421389579773
    outflow_accuracy_metric: 0.4237859845161438
    outflow_f1_metric: 0.41367894411087036
    outflow_aucroc_metric: 0.8592628836631775
    val_loss       : 3.7193154222086857
    val_inflow_loss: 1.5436650483231795
    val_outflow_loss: 2.17565036133716
    val_inflow_accuracy_metric: 0.42932772636413574
    val_inflow_f1_metric: 0.4208371937274933
    val_inflow_aucroc_metric: 0.8251832127571106
    val_outflow_accuracy_metric: 0.22355742752552032
    val_outflow_f1_metric: 0.19212698936462402
    val_outflow_aucroc_metric: 0.6729296445846558
Train Epoch: 28 [0/100088 (0%)] Loss: 3.148296
Train Epoch: 28 [11264/100088 (11%)] Loss: 3.014355
Train Epoch: 28 [22528/100088 (23%)] Loss: 3.070912
Train Epoch: 28 [33792/100088 (34%)] Loss: 3.105695
Train Epoch: 28 [45056/100088 (45%)] Loss: 3.116452
Train Epoch: 28 [56320/100088 (56%)] Loss: 3.133494
Train Epoch: 28 [67584/100088 (68%)] Loss: 3.198799
Train Epoch: 28 [78848/100088 (79%)] Loss: 3.209790
Train Epoch: 28 [90112/100088 (90%)] Loss: 3.149601
    epoch          : 28
    loss           : 3.090805951429873
    inflow_loss    : 1.6163153788264917
    outflow_loss   : 1.4744905774690666
    inflow_accuracy_metric: 0.4039895534515381
    inflow_f1_metric: 0.3834981322288513
    inflow_aucroc_metric: 0.8170148730278015
    outflow_accuracy_metric: 0.4254424273967743
    outflow_f1_metric: 0.41523075103759766
    outflow_aucroc_metric: 0.8606775999069214
    val_loss       : 3.5133774782481946
    val_inflow_loss: 1.5711614489555359
    val_outflow_loss: 1.9422160355668319
    val_inflow_accuracy_metric: 0.43509459495544434
    val_inflow_f1_metric: 0.4294669032096863
    val_inflow_aucroc_metric: 0.8080927133560181
    val_outflow_accuracy_metric: 0.22132675349712372
    val_outflow_f1_metric: 0.20420819520950317
    val_outflow_aucroc_metric: 0.6700384020805359
Train Epoch: 29 [0/100088 (0%)] Loss: 3.123191
Train Epoch: 29 [11264/100088 (11%)] Loss: 3.001221
Train Epoch: 29 [22528/100088 (23%)] Loss: 3.081833
Train Epoch: 29 [33792/100088 (34%)] Loss: 3.079399
Train Epoch: 29 [45056/100088 (45%)] Loss: 3.080747
Train Epoch: 29 [56320/100088 (56%)] Loss: 3.064060
Train Epoch: 29 [67584/100088 (68%)] Loss: 3.178159
Train Epoch: 29 [78848/100088 (79%)] Loss: 3.038512
Train Epoch: 29 [90112/100088 (90%)] Loss: 3.042844
    epoch          : 29
    loss           : 3.0928243982548618
    inflow_loss    : 1.610439110775383
    outflow_loss   : 1.4823852856548465
    inflow_accuracy_metric: 0.40653353929519653
    inflow_f1_metric: 0.3862551748752594
    inflow_aucroc_metric: 0.8184695839881897
    outflow_accuracy_metric: 0.4215773344039917
    outflow_f1_metric: 0.41110605001449585
    outflow_aucroc_metric: 0.8590426445007324
    val_loss       : 3.6341587995228015
    val_inflow_loss: 1.5904819777137356
    val_outflow_loss: 2.043676834357412
    val_inflow_accuracy_metric: 0.424900621175766
    val_inflow_f1_metric: 0.4257548153400421
    val_inflow_aucroc_metric: 0.8197154402732849
    val_outflow_accuracy_metric: 0.21922972798347473
    val_outflow_f1_metric: 0.1912820190191269
    val_outflow_aucroc_metric: 0.6736416220664978
Train Epoch: 30 [0/100088 (0%)] Loss: 3.226126
Train Epoch: 30 [11264/100088 (11%)] Loss: 3.120960
Train Epoch: 30 [22528/100088 (23%)] Loss: 3.022153
Train Epoch: 30 [33792/100088 (34%)] Loss: 3.056271
Train Epoch: 30 [45056/100088 (45%)] Loss: 3.016089
Train Epoch: 30 [56320/100088 (56%)] Loss: 3.060061
Train Epoch: 30 [67584/100088 (68%)] Loss: 3.131498
Train Epoch: 30 [78848/100088 (79%)] Loss: 3.105840
Train Epoch: 30 [90112/100088 (90%)] Loss: 3.133984
    epoch          : 30
    loss           : 3.0814880972005882
    inflow_loss    : 1.6101429486761287
    outflow_loss   : 1.4713451539983555
    inflow_accuracy_metric: 0.40651360154151917
    inflow_f1_metric: 0.38682791590690613
    inflow_aucroc_metric: 0.8182127475738525
    outflow_accuracy_metric: 0.42585355043411255
    outflow_f1_metric: 0.4155569076538086
    outflow_aucroc_metric: 0.8610735535621643
    val_loss       : 3.6277745397467362
    val_inflow_loss: 1.5467657697828192
    val_outflow_loss: 2.0810087636897436
    val_inflow_accuracy_metric: 0.42583605647087097
    val_inflow_f1_metric: 0.41146358847618103
    val_inflow_aucroc_metric: 0.817184329032898
    val_outflow_accuracy_metric: 0.2210080772638321
    val_outflow_f1_metric: 0.1908261775970459
    val_outflow_aucroc_metric: 0.6809964179992676
Train Epoch: 31 [0/100088 (0%)] Loss: 2.928708
Train Epoch: 31 [11264/100088 (11%)] Loss: 3.155251
Train Epoch: 31 [22528/100088 (23%)] Loss: 3.068487
Train Epoch: 31 [33792/100088 (34%)] Loss: 3.036760
Train Epoch: 31 [45056/100088 (45%)] Loss: 3.085895
Train Epoch: 31 [56320/100088 (56%)] Loss: 3.196717
Train Epoch: 31 [67584/100088 (68%)] Loss: 3.064582
Train Epoch: 31 [78848/100088 (79%)] Loss: 3.018843
Train Epoch: 31 [90112/100088 (90%)] Loss: 3.084771
    epoch          : 31
    loss           : 3.078918064127163
    inflow_loss    : 1.605771620662845
    outflow_loss   : 1.4731464404232648
    inflow_accuracy_metric: 0.40814656019210815
    inflow_f1_metric: 0.3886594772338867
    inflow_aucroc_metric: 0.8197550177574158
    outflow_accuracy_metric: 0.4261557459831238
    outflow_f1_metric: 0.41502270102500916
    outflow_aucroc_metric: 0.8608922958374023
    val_loss       : 3.688093486585115
    val_inflow_loss: 1.558762384088416
    val_outflow_loss: 2.1293310993596126
    val_inflow_accuracy_metric: 0.43058526515960693
    val_inflow_f1_metric: 0.42896902561187744
    val_inflow_aucroc_metric: 0.8225309252738953
    val_outflow_accuracy_metric: 0.23479647934436798
    val_outflow_f1_metric: 0.20640048384666443
    val_outflow_aucroc_metric: 0.6836662292480469
Train Epoch: 32 [0/100088 (0%)] Loss: 3.119440
Train Epoch: 32 [11264/100088 (11%)] Loss: 3.110550
Train Epoch: 32 [22528/100088 (23%)] Loss: 3.145696
Train Epoch: 32 [33792/100088 (34%)] Loss: 3.071704
Train Epoch: 32 [45056/100088 (45%)] Loss: 3.167555
Train Epoch: 32 [56320/100088 (56%)] Loss: 2.968492
Train Epoch: 32 [67584/100088 (68%)] Loss: 3.123116
Train Epoch: 32 [78848/100088 (79%)] Loss: 3.027404
Train Epoch: 32 [90112/100088 (90%)] Loss: 3.059982
    epoch          : 32
    loss           : 3.0721903236544863
    inflow_loss    : 1.6030724693317802
    outflow_loss   : 1.46911785797197
    inflow_accuracy_metric: 0.4090070426464081
    inflow_f1_metric: 0.3884831964969635
    inflow_aucroc_metric: 0.8203275799751282
    outflow_accuracy_metric: 0.42607346177101135
    outflow_f1_metric: 0.4156104028224945
    outflow_aucroc_metric: 0.8617510795593262
    val_loss       : 3.7659203127810827
    val_inflow_loss: 1.5454633016335337
    val_outflow_loss: 2.220457014284636
    val_inflow_accuracy_metric: 0.42382124066352844
    val_inflow_f1_metric: 0.42380663752555847
    val_inflow_aucroc_metric: 0.8191571831703186
    val_outflow_accuracy_metric: 0.23612253367900848
    val_outflow_f1_metric: 0.20737798511981964
    val_outflow_aucroc_metric: 0.6782681345939636
Train Epoch: 33 [0/100088 (0%)] Loss: 3.067383
Train Epoch: 33 [11264/100088 (11%)] Loss: 3.068803
Train Epoch: 33 [22528/100088 (23%)] Loss: 3.099926
Train Epoch: 33 [33792/100088 (34%)] Loss: 3.026384
Train Epoch: 33 [45056/100088 (45%)] Loss: 3.104717
Train Epoch: 33 [56320/100088 (56%)] Loss: 3.044159
Train Epoch: 33 [67584/100088 (68%)] Loss: 2.961405
Train Epoch: 33 [78848/100088 (79%)] Loss: 3.084922
Train Epoch: 33 [90112/100088 (90%)] Loss: 3.065526
    epoch          : 33
    loss           : 3.066821858590963
    inflow_loss    : 1.6014491477791144
    outflow_loss   : 1.4653727138529018
    inflow_accuracy_metric: 0.41026681661605835
    inflow_f1_metric: 0.39033183455467224
    inflow_aucroc_metric: 0.8203458189964294
    outflow_accuracy_metric: 0.42780187726020813
    outflow_f1_metric: 0.41756823658943176
    outflow_aucroc_metric: 0.8622686862945557
    val_loss       : 3.6538411504343937
    val_inflow_loss: 1.5374973447699296
    val_outflow_loss: 2.1163438182128105
    val_inflow_accuracy_metric: 0.4335697591304779
    val_inflow_f1_metric: 0.4239158034324646
    val_inflow_aucroc_metric: 0.8250911831855774
    val_outflow_accuracy_metric: 0.2167283445596695
    val_outflow_f1_metric: 0.1980733424425125
    val_outflow_aucroc_metric: 0.6681203246116638
Train Epoch: 34 [0/100088 (0%)] Loss: 3.029689
Train Epoch: 34 [11264/100088 (11%)] Loss: 3.088392
Train Epoch: 34 [22528/100088 (23%)] Loss: 2.930755
Train Epoch: 34 [33792/100088 (34%)] Loss: 3.055540
Train Epoch: 34 [45056/100088 (45%)] Loss: 2.956242
Train Epoch: 34 [56320/100088 (56%)] Loss: 3.052791
Train Epoch: 34 [67584/100088 (68%)] Loss: 3.093993
Train Epoch: 34 [78848/100088 (79%)] Loss: 3.113242
Train Epoch: 34 [90112/100088 (90%)] Loss: 3.026014
    epoch          : 34
    loss           : 3.065455689722178
    inflow_loss    : 1.5988508876489134
    outflow_loss   : 1.466604799640422
    inflow_accuracy_metric: 0.4112350344657898
    inflow_f1_metric: 0.3899976313114166
    inflow_aucroc_metric: 0.8211227655410767
    outflow_accuracy_metric: 0.4270056486129761
    outflow_f1_metric: 0.4166112244129181
    outflow_aucroc_metric: 0.8622444272041321
    val_loss       : 3.680402718092266
    val_inflow_loss: 1.592505527170081
    val_outflow_loss: 2.0878971877850985
    val_inflow_accuracy_metric: 0.4185444116592407
    val_inflow_f1_metric: 0.41320645809173584
    val_inflow_aucroc_metric: 0.8088638782501221
    val_outflow_accuracy_metric: 0.22777891159057617
    val_outflow_f1_metric: 0.2054833322763443
    val_outflow_aucroc_metric: 0.6773485541343689
Train Epoch: 35 [0/100088 (0%)] Loss: 3.095588
Train Epoch: 35 [11264/100088 (11%)] Loss: 3.026831
Train Epoch: 35 [22528/100088 (23%)] Loss: 2.971688
Train Epoch: 35 [33792/100088 (34%)] Loss: 3.056622
Train Epoch: 35 [45056/100088 (45%)] Loss: 3.125958
Train Epoch: 35 [56320/100088 (56%)] Loss: 3.025871
Train Epoch: 35 [67584/100088 (68%)] Loss: 2.922163
Train Epoch: 35 [78848/100088 (79%)] Loss: 3.016171
Train Epoch: 35 [90112/100088 (90%)] Loss: 3.148861
    epoch          : 35
    loss           : 3.063265108332342
    inflow_loss    : 1.601134373217213
    outflow_loss   : 1.4621307326822865
    inflow_accuracy_metric: 0.4100501835346222
    inflow_f1_metric: 0.38976314663887024
    inflow_aucroc_metric: 0.8207707405090332
    outflow_accuracy_metric: 0.42952707409858704
    outflow_f1_metric: 0.41893526911735535
    outflow_aucroc_metric: 0.8632436990737915
    val_loss       : 3.6384281296479073
    val_inflow_loss: 1.5606927652108042
    val_outflow_loss: 2.0777353613000167
    val_inflow_accuracy_metric: 0.43216490745544434
    val_inflow_f1_metric: 0.42614805698394775
    val_inflow_aucroc_metric: 0.8185190558433533
    val_outflow_accuracy_metric: 0.22494517266750336
    val_outflow_f1_metric: 0.19352342188358307
    val_outflow_aucroc_metric: 0.6773293614387512
Train Epoch: 36 [0/100088 (0%)] Loss: 2.944024
Train Epoch: 36 [11264/100088 (11%)] Loss: 3.131483
Train Epoch: 36 [22528/100088 (23%)] Loss: 3.002393
Train Epoch: 36 [33792/100088 (34%)] Loss: 3.095688
Train Epoch: 36 [45056/100088 (45%)] Loss: 3.050459
Train Epoch: 36 [56320/100088 (56%)] Loss: 3.063020
Train Epoch: 36 [67584/100088 (68%)] Loss: 2.975384
Train Epoch: 36 [78848/100088 (79%)] Loss: 3.007349
Train Epoch: 36 [90112/100088 (90%)] Loss: 2.928861
    epoch          : 36
    loss           : 3.049391359699016
    inflow_loss    : 1.5940156493868147
    outflow_loss   : 1.4553757078793583
    inflow_accuracy_metric: 0.41201743483543396
    inflow_f1_metric: 0.39158281683921814
    inflow_aucroc_metric: 0.8221970200538635
    outflow_accuracy_metric: 0.4304930567741394
    outflow_f1_metric: 0.4199633300304413
    outflow_aucroc_metric: 0.8643224835395813
    val_loss       : 3.5381528766531694
    val_inflow_loss: 1.5391990950233059
    val_outflow_loss: 1.9989537973152964
    val_inflow_accuracy_metric: 0.42878633737564087
    val_inflow_f1_metric: 0.42276060581207275
    val_inflow_aucroc_metric: 0.824563205242157
    val_outflow_accuracy_metric: 0.21861979365348816
    val_outflow_f1_metric: 0.1981143355369568
    val_outflow_aucroc_metric: 0.6773821115493774
Train Epoch: 37 [0/100088 (0%)] Loss: 3.136623
Train Epoch: 37 [11264/100088 (11%)] Loss: 2.981922
Train Epoch: 37 [22528/100088 (23%)] Loss: 3.052390
Train Epoch: 37 [33792/100088 (34%)] Loss: 2.950317
Train Epoch: 37 [45056/100088 (45%)] Loss: 3.058694
Train Epoch: 37 [56320/100088 (56%)] Loss: 3.066342
Train Epoch: 37 [67584/100088 (68%)] Loss: 3.114100
Train Epoch: 37 [78848/100088 (79%)] Loss: 2.984420
Train Epoch: 37 [90112/100088 (90%)] Loss: 3.127018
    epoch          : 37
    loss           : 3.0465787272064055
    inflow_loss    : 1.591014833474646
    outflow_loss   : 1.4555638852168102
    inflow_accuracy_metric: 0.41420555114746094
    inflow_f1_metric: 0.39402493834495544
    inflow_aucroc_metric: 0.8228525519371033
    outflow_accuracy_metric: 0.43075019121170044
    outflow_f1_metric: 0.4202011227607727
    outflow_aucroc_metric: 0.8642919659614563
    val_loss       : 3.7009458541870117
    val_inflow_loss: 1.5666505412051552
    val_outflow_loss: 2.1342953255302026
    val_inflow_accuracy_metric: 0.4308285415172577
    val_inflow_f1_metric: 0.42658907175064087
    val_inflow_aucroc_metric: 0.8158928751945496
    val_outflow_accuracy_metric: 0.23295985162258148
    val_outflow_f1_metric: 0.20090453326702118
    val_outflow_aucroc_metric: 0.6775253415107727
Train Epoch: 38 [0/100088 (0%)] Loss: 2.947761
Train Epoch: 38 [11264/100088 (11%)] Loss: 3.036726
Train Epoch: 38 [22528/100088 (23%)] Loss: 3.170329
Train Epoch: 38 [33792/100088 (34%)] Loss: 2.984590
Train Epoch: 38 [45056/100088 (45%)] Loss: 3.078424
Train Epoch: 38 [56320/100088 (56%)] Loss: 3.065026
Train Epoch: 38 [67584/100088 (68%)] Loss: 3.143494
Train Epoch: 38 [78848/100088 (79%)] Loss: 3.066414
Train Epoch: 38 [90112/100088 (90%)] Loss: 3.067280
    epoch          : 38
    loss           : 3.0440088449692237
    inflow_loss    : 1.5876146749574311
    outflow_loss   : 1.4563941675789502
    inflow_accuracy_metric: 0.4142029881477356
    inflow_f1_metric: 0.3933923542499542
    inflow_aucroc_metric: 0.8240479826927185
    outflow_accuracy_metric: 0.4293486773967743
    outflow_f1_metric: 0.41812658309936523
    outflow_aucroc_metric: 0.8642114996910095
    val_loss       : 3.524592725854171
    val_inflow_loss: 1.5622533559799194
    val_outflow_loss: 1.9623393636000783
    val_inflow_accuracy_metric: 0.43220943212509155
    val_inflow_f1_metric: 0.4272041320800781
    val_inflow_aucroc_metric: 0.8232505917549133
    val_outflow_accuracy_metric: 0.22831347584724426
    val_outflow_f1_metric: 0.21119312942028046
    val_outflow_aucroc_metric: 0.6773260831832886
Train Epoch: 39 [0/100088 (0%)] Loss: 2.991230
Train Epoch: 39 [11264/100088 (11%)] Loss: 3.072899
Train Epoch: 39 [22528/100088 (23%)] Loss: 2.928547
Train Epoch: 39 [33792/100088 (34%)] Loss: 2.888864
Train Epoch: 39 [45056/100088 (45%)] Loss: 2.998649
Train Epoch: 39 [56320/100088 (56%)] Loss: 2.991427
Train Epoch: 39 [67584/100088 (68%)] Loss: 3.004102
Train Epoch: 39 [78848/100088 (79%)] Loss: 3.021000
Train Epoch: 39 [90112/100088 (90%)] Loss: 3.014055
    epoch          : 39
    loss           : 3.0386353427050063
    inflow_loss    : 1.5894555674523723
    outflow_loss   : 1.449179764913053
    inflow_accuracy_metric: 0.4118097424507141
    inflow_f1_metric: 0.39095959067344666
    inflow_aucroc_metric: 0.8236399292945862
    outflow_accuracy_metric: 0.43199774622917175
    outflow_f1_metric: 0.42138659954071045
    outflow_aucroc_metric: 0.8657121062278748
    val_loss       : 3.6747981560857674
    val_inflow_loss: 1.5684835189267208
    val_outflow_loss: 2.1063146214736137
    val_inflow_accuracy_metric: 0.42879316210746765
    val_inflow_f1_metric: 0.42136654257774353
    val_inflow_aucroc_metric: 0.8189247846603394
    val_outflow_accuracy_metric: 0.24026177823543549
    val_outflow_f1_metric: 0.22032178938388824
    val_outflow_aucroc_metric: 0.6781139373779297
Train Epoch: 40 [0/100088 (0%)] Loss: 3.121905
Train Epoch: 40 [11264/100088 (11%)] Loss: 2.885423
Train Epoch: 40 [22528/100088 (23%)] Loss: 2.929505
Train Epoch: 40 [33792/100088 (34%)] Loss: 2.994102
Train Epoch: 40 [45056/100088 (45%)] Loss: 3.073343
Train Epoch: 40 [56320/100088 (56%)] Loss: 2.999439
Train Epoch: 40 [67584/100088 (68%)] Loss: 3.079226
Train Epoch: 40 [78848/100088 (79%)] Loss: 3.029098
Train Epoch: 40 [90112/100088 (90%)] Loss: 3.116069
    epoch          : 40
    loss           : 3.0381685422391307
    inflow_loss    : 1.5883192170639426
    outflow_loss   : 1.449849314227396
    inflow_accuracy_metric: 0.4145205616950989
    inflow_f1_metric: 0.3944871723651886
    inflow_aucroc_metric: 0.8237602710723877
    outflow_accuracy_metric: 0.43195754289627075
    outflow_f1_metric: 0.4214652478694916
    outflow_aucroc_metric: 0.8654766082763672
    val_loss       : 3.622796102573997
    val_inflow_loss: 1.5645658593428762
    val_outflow_loss: 2.0582302463682076
    val_inflow_accuracy_metric: 0.4315515458583832
    val_inflow_f1_metric: 0.41547635197639465
    val_inflow_aucroc_metric: 0.8126798868179321
    val_outflow_accuracy_metric: 0.23469708859920502
    val_outflow_f1_metric: 0.21153181791305542
    val_outflow_aucroc_metric: 0.6835516691207886
Train Epoch: 41 [0/100088 (0%)] Loss: 3.106515
Train Epoch: 41 [11264/100088 (11%)] Loss: 2.993269
Train Epoch: 41 [22528/100088 (23%)] Loss: 2.940098
Train Epoch: 41 [33792/100088 (34%)] Loss: 3.024631
Train Epoch: 41 [45056/100088 (45%)] Loss: 2.906384
Train Epoch: 41 [56320/100088 (56%)] Loss: 3.023332
Train Epoch: 41 [67584/100088 (68%)] Loss: 3.126197
Train Epoch: 41 [78848/100088 (79%)] Loss: 2.992996
Train Epoch: 41 [90112/100088 (90%)] Loss: 3.032051
    epoch          : 41
    loss           : 3.032689549485031
    inflow_loss    : 1.5821208321318334
    outflow_loss   : 1.4505687076218274
    inflow_accuracy_metric: 0.416806697845459
    inflow_f1_metric: 0.3964003324508667
    inflow_aucroc_metric: 0.8252648115158081
    outflow_accuracy_metric: 0.43197011947631836
    outflow_f1_metric: 0.42143282294273376
    outflow_aucroc_metric: 0.8653109073638916
    val_loss       : 3.7462647400404276
    val_inflow_loss: 1.575787525427969
    val_outflow_loss: 2.1704772083382857
    val_inflow_accuracy_metric: 0.42418792843818665
    val_inflow_f1_metric: 0.41548794507980347
    val_inflow_aucroc_metric: 0.8141319155693054
    val_outflow_accuracy_metric: 0.2277275174856186
    val_outflow_f1_metric: 0.19359369575977325
    val_outflow_aucroc_metric: 0.6727103590965271
Train Epoch: 42 [0/100088 (0%)] Loss: 3.041062
Train Epoch: 42 [11264/100088 (11%)] Loss: 3.040139
Train Epoch: 42 [22528/100088 (23%)] Loss: 3.102002
Train Epoch: 42 [33792/100088 (34%)] Loss: 2.977808
Train Epoch: 42 [45056/100088 (45%)] Loss: 3.038546
Train Epoch: 42 [56320/100088 (56%)] Loss: 3.087817
Train Epoch: 42 [67584/100088 (68%)] Loss: 3.012889
Train Epoch: 42 [78848/100088 (79%)] Loss: 2.953813
Train Epoch: 42 [90112/100088 (90%)] Loss: 3.143705
    epoch          : 42
    loss           : 3.021949226758918
    inflow_loss    : 1.5797421019904467
    outflow_loss   : 1.4422071205109965
    inflow_accuracy_metric: 0.4186241626739502
    inflow_f1_metric: 0.3988731801509857
    inflow_aucroc_metric: 0.8262432217597961
    outflow_accuracy_metric: 0.4334140717983246
    outflow_f1_metric: 0.42298194766044617
    outflow_aucroc_metric: 0.8668307065963745
    val_loss       : 3.79969490829267
    val_inflow_loss: 1.5756699631088658
    val_outflow_loss: 2.224024954595064
    val_inflow_accuracy_metric: 0.4311814606189728
    val_inflow_f1_metric: 0.42365601658821106
    val_inflow_aucroc_metric: 0.8166294097900391
    val_outflow_accuracy_metric: 0.22275561094284058
    val_outflow_f1_metric: 0.1957125961780548
    val_outflow_aucroc_metric: 0.670876145362854
Train Epoch: 43 [0/100088 (0%)] Loss: 3.094388
Train Epoch: 43 [11264/100088 (11%)] Loss: 3.030348
Train Epoch: 43 [22528/100088 (23%)] Loss: 3.029862
Train Epoch: 43 [33792/100088 (34%)] Loss: 3.046073
Train Epoch: 43 [45056/100088 (45%)] Loss: 3.112723
Train Epoch: 43 [56320/100088 (56%)] Loss: 2.964103
Train Epoch: 43 [67584/100088 (68%)] Loss: 2.893970
Train Epoch: 43 [78848/100088 (79%)] Loss: 3.126182
Train Epoch: 43 [90112/100088 (90%)] Loss: 3.023277
    epoch          : 43
    loss           : 3.0214746971519624
    inflow_loss    : 1.5794688329404714
    outflow_loss   : 1.4420058660361232
    inflow_accuracy_metric: 0.41760969161987305
    inflow_f1_metric: 0.396994024515152
    inflow_aucroc_metric: 0.8259080052375793
    outflow_accuracy_metric: 0.43482136726379395
    outflow_f1_metric: 0.4240990877151489
    outflow_aucroc_metric: 0.8671600818634033
    val_loss       : 3.69247829914093
    val_inflow_loss: 1.558887713833859
    val_outflow_loss: 2.1335905664845516
    val_inflow_accuracy_metric: 0.4239754378795624
    val_inflow_f1_metric: 0.4133719503879547
    val_inflow_aucroc_metric: 0.8193876147270203
    val_outflow_accuracy_metric: 0.22458882629871368
    val_outflow_f1_metric: 0.19104918837547302
    val_outflow_aucroc_metric: 0.6777685284614563
Train Epoch: 44 [0/100088 (0%)] Loss: 3.015709
Train Epoch: 44 [11264/100088 (11%)] Loss: 2.971053
Train Epoch: 44 [22528/100088 (23%)] Loss: 3.009667
Train Epoch: 44 [33792/100088 (34%)] Loss: 2.976362
Train Epoch: 44 [45056/100088 (45%)] Loss: 2.943251
Train Epoch: 44 [56320/100088 (56%)] Loss: 3.093178
Train Epoch: 44 [67584/100088 (68%)] Loss: 3.101770
Train Epoch: 44 [78848/100088 (79%)] Loss: 3.115868
Train Epoch: 44 [90112/100088 (90%)] Loss: 2.997267
    epoch          : 44
    loss           : 3.0159154303219853
    inflow_loss    : 1.5766993183262494
    outflow_loss   : 1.4392161089546827
    inflow_accuracy_metric: 0.41845637559890747
    inflow_f1_metric: 0.39804577827453613
    inflow_aucroc_metric: 0.8268705010414124
    outflow_accuracy_metric: 0.43489015102386475
    outflow_f1_metric: 0.42367666959762573
    outflow_aucroc_metric: 0.8676167726516724
    val_loss       : 3.6717266973696256
    val_inflow_loss: 1.567825060141714
    val_outflow_loss: 2.1039016309537386
    val_inflow_accuracy_metric: 0.4191269278526306
    val_inflow_f1_metric: 0.40442144870758057
    val_inflow_aucroc_metric: 0.8145866394042969
    val_outflow_accuracy_metric: 0.23448464274406433
    val_outflow_f1_metric: 0.21331889927387238
    val_outflow_aucroc_metric: 0.6745891571044922
Train Epoch: 45 [0/100088 (0%)] Loss: 2.979847
Train Epoch: 45 [11264/100088 (11%)] Loss: 2.933748
Train Epoch: 45 [22528/100088 (23%)] Loss: 3.075696
Train Epoch: 45 [33792/100088 (34%)] Loss: 2.994923
Train Epoch: 45 [45056/100088 (45%)] Loss: 2.956447
Train Epoch: 45 [56320/100088 (56%)] Loss: 2.958085
Train Epoch: 45 [67584/100088 (68%)] Loss: 3.007425
Train Epoch: 45 [78848/100088 (79%)] Loss: 3.061509
Train Epoch: 45 [90112/100088 (90%)] Loss: 2.974857
    epoch          : 45
    loss           : 3.006435264130028
    inflow_loss    : 1.5718913984541991
    outflow_loss   : 1.4345438632429863
    inflow_accuracy_metric: 0.4197026491165161
    inflow_f1_metric: 0.39948517084121704
    inflow_aucroc_metric: 0.8279991745948792
    outflow_accuracy_metric: 0.4375768303871155
    outflow_f1_metric: 0.42758458852767944
    outflow_aucroc_metric: 0.8682888150215149
    val_loss       : 3.61646170365183
    val_inflow_loss: 1.5621088272646855
    val_outflow_loss: 2.0543528763871444
    val_inflow_accuracy_metric: 0.4221114218235016
    val_inflow_f1_metric: 0.4074910581111908
    val_inflow_aucroc_metric: 0.8183574676513672
    val_outflow_accuracy_metric: 0.2303282618522644
    val_outflow_f1_metric: 0.20657528936862946
    val_outflow_aucroc_metric: 0.6769936680793762
Train Epoch: 46 [0/100088 (0%)] Loss: 3.024797
Train Epoch: 46 [11264/100088 (11%)] Loss: 3.014172
Train Epoch: 46 [22528/100088 (23%)] Loss: 3.018409
Train Epoch: 46 [33792/100088 (34%)] Loss: 2.993343
Train Epoch: 46 [45056/100088 (45%)] Loss: 2.992427
Train Epoch: 46 [56320/100088 (56%)] Loss: 2.931598
Train Epoch: 46 [67584/100088 (68%)] Loss: 3.044553
Train Epoch: 46 [78848/100088 (79%)] Loss: 2.962822
Train Epoch: 46 [90112/100088 (90%)] Loss: 2.944866
    epoch          : 46
    loss           : 2.9967083566042843
    inflow_loss    : 1.5693152273187831
    outflow_loss   : 1.4273931286772903
    inflow_accuracy_metric: 0.4208190143108368
    inflow_f1_metric: 0.4006149470806122
    inflow_aucroc_metric: 0.8285739421844482
    outflow_accuracy_metric: 0.4384048581123352
    outflow_f1_metric: 0.42785289883613586
    outflow_aucroc_metric: 0.8696030378341675
    val_loss       : 3.827986064710115
    val_inflow_loss: 1.6065956040432579
    val_outflow_loss: 2.2213904543926843
    val_inflow_accuracy_metric: 0.42877262830734253
    val_inflow_f1_metric: 0.42223218083381653
    val_inflow_aucroc_metric: 0.8148585557937622
    val_outflow_accuracy_metric: 0.23646177351474762
    val_outflow_f1_metric: 0.20888182520866394
    val_outflow_aucroc_metric: 0.6777703762054443
Train Epoch: 47 [0/100088 (0%)] Loss: 3.002074
Train Epoch: 47 [11264/100088 (11%)] Loss: 2.912627
Train Epoch: 47 [22528/100088 (23%)] Loss: 2.952917
Train Epoch: 47 [33792/100088 (34%)] Loss: 2.973117
Train Epoch: 47 [45056/100088 (45%)] Loss: 3.006725
Train Epoch: 47 [56320/100088 (56%)] Loss: 3.018801
Train Epoch: 47 [67584/100088 (68%)] Loss: 2.963299
Train Epoch: 47 [78848/100088 (79%)] Loss: 3.011463
Train Epoch: 47 [90112/100088 (90%)] Loss: 2.945264
    epoch          : 47
    loss           : 2.9950743049991373
    inflow_loss    : 1.5657501062568353
    outflow_loss   : 1.4293241957012488
    inflow_accuracy_metric: 0.4221057891845703
    inflow_f1_metric: 0.40207919478416443
    inflow_aucroc_metric: 0.8294383883476257
    outflow_accuracy_metric: 0.436960905790329
    outflow_f1_metric: 0.42715999484062195
    outflow_aucroc_metric: 0.8695350289344788
    val_loss       : 3.801120814524199
    val_inflow_loss: 1.598782319771616
    val_outflow_loss: 2.202338507300929
    val_inflow_accuracy_metric: 0.425037682056427
    val_inflow_f1_metric: 0.41650518774986267
    val_inflow_aucroc_metric: 0.8117913007736206
    val_outflow_accuracy_metric: 0.2350945770740509
    val_outflow_f1_metric: 0.2030545324087143
    val_outflow_aucroc_metric: 0.6772258877754211
Train Epoch: 48 [0/100088 (0%)] Loss: 2.983417
Train Epoch: 48 [11264/100088 (11%)] Loss: 2.936841
Train Epoch: 48 [22528/100088 (23%)] Loss: 3.000007
Train Epoch: 48 [33792/100088 (34%)] Loss: 2.975246
Train Epoch: 48 [45056/100088 (45%)] Loss: 3.146809
Train Epoch: 48 [56320/100088 (56%)] Loss: 2.931904
Train Epoch: 48 [67584/100088 (68%)] Loss: 3.065138
Train Epoch: 48 [78848/100088 (79%)] Loss: 3.029353
Train Epoch: 48 [90112/100088 (90%)] Loss: 2.986589
    epoch          : 48
    loss           : 3.0145231886785857
    inflow_loss    : 1.5901770883676958
    outflow_loss   : 1.4243461015273113
    inflow_accuracy_metric: 0.41280531883239746
    inflow_f1_metric: 0.3927629292011261
    inflow_aucroc_metric: 0.8240501880645752
    outflow_accuracy_metric: 0.4401586651802063
    outflow_f1_metric: 0.4299107789993286
    outflow_aucroc_metric: 0.8704999089241028
    val_loss       : 3.6920032501220703
    val_inflow_loss: 1.5773150230708874
    val_outflow_loss: 2.114688233325356
    val_inflow_accuracy_metric: 0.4224472641944885
    val_inflow_f1_metric: 0.4049636125564575
    val_inflow_aucroc_metric: 0.8119648098945618
    val_outflow_accuracy_metric: 0.22878290712833405
    val_outflow_f1_metric: 0.20647381246089935
    val_outflow_aucroc_metric: 0.6781561374664307
Train Epoch: 49 [0/100088 (0%)] Loss: 2.980509
Train Epoch: 49 [11264/100088 (11%)] Loss: 2.997355
Train Epoch: 49 [22528/100088 (23%)] Loss: 3.100036
Train Epoch: 49 [33792/100088 (34%)] Loss: 2.981282
Train Epoch: 49 [45056/100088 (45%)] Loss: 3.069091
Train Epoch: 49 [56320/100088 (56%)] Loss: 2.957940
Train Epoch: 49 [67584/100088 (68%)] Loss: 2.971471
Train Epoch: 49 [78848/100088 (79%)] Loss: 3.011375
Train Epoch: 49 [90112/100088 (90%)] Loss: 3.002742
    epoch          : 49
    loss           : 2.9844833989532624
    inflow_loss    : 1.562236170379483
    outflow_loss   : 1.4222472291819903
    inflow_accuracy_metric: 0.4239910840988159
    inflow_f1_metric: 0.4039170742034912
    inflow_aucroc_metric: 0.8298356533050537
    outflow_accuracy_metric: 0.44039177894592285
    outflow_f1_metric: 0.43008336424827576
    outflow_aucroc_metric: 0.870919406414032
    val_loss       : 3.824074751452396
    val_inflow_loss: 1.577255616062566
    val_outflow_loss: 2.2468191385269165
    val_inflow_accuracy_metric: 0.41591283679008484
    val_inflow_f1_metric: 0.3968699276447296
    val_inflow_aucroc_metric: 0.809660017490387
    val_outflow_accuracy_metric: 0.23931264877319336
    val_outflow_f1_metric: 0.21592725813388824
    val_outflow_aucroc_metric: 0.6798433065414429
Validation performance didn't improve for 30 epochs. Training stops.
/home/wchao/anaconda3/envs/skillkg/lib/python3.7/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                       epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:      inflow_accuracy_metric ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:        inflow_aucroc_metric ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:            inflow_f1_metric ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                 inflow_loss ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                        loss ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:     outflow_accuracy_metric ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:       outflow_aucroc_metric ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:           outflow_f1_metric ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                outflow_loss ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  val_inflow_accuracy_metric ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá
wandb:    val_inflow_aucroc_metric ‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:        val_inflow_f1_metric ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá
wandb:             val_inflow_loss ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ
wandb:                    val_loss ‚ñà‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÑ
wandb: val_outflow_accuracy_metric ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà
wandb:   val_outflow_aucroc_metric ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:       val_outflow_f1_metric ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñà‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà
wandb:            val_outflow_loss ‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÑ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñá
wandb: 
wandb: Run summary:
wandb:                       epoch 49
wandb:      inflow_accuracy_metric 0.42399
wandb:        inflow_aucroc_metric 0.82984
wandb:            inflow_f1_metric 0.40392
wandb:                 inflow_loss 1.56224
wandb:                        loss 2.98448
wandb:     outflow_accuracy_metric 0.44039
wandb:       outflow_aucroc_metric 0.87092
wandb:           outflow_f1_metric 0.43008
wandb:                outflow_loss 1.42225
wandb:  val_inflow_accuracy_metric 0.41591
wandb:    val_inflow_aucroc_metric 0.80966
wandb:        val_inflow_f1_metric 0.39687
wandb:             val_inflow_loss 1.57726
wandb:                    val_loss 3.82407
wandb: val_outflow_accuracy_metric 0.23931
wandb:   val_outflow_aucroc_metric 0.67984
wandb:       val_outflow_f1_metric 0.21593
wandb:            val_outflow_loss 2.24682
wandb: 
wandb: Synced LSTM: https://wandb.ai/wchao/SKillTrend/runs/2dz53t3p
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230210_171409-2dz53t3p/logs
